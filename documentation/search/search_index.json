{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"OpenSage Development Wiki","text":"<p>Welcome to the OpenSage Development Documentation!</p> <p>OpenSage (Open Self-programming Agent Generation Engine) is an AI agent framework built on top of Google ADK.</p>"},{"location":"#self-generating-agent-topology","title":"Self-generating Agent Topology","text":"<ul> <li>Dynamic creation/execution/termination of sub-agents</li> <li>Vertical topology and horizontal topology</li> <li>Agent ensemble mechanism</li> </ul>"},{"location":"#dynamic-tool-synthesis","title":"Dynamic Tool Synthesis","text":"<ul> <li>Dynamic tool synthesis and management</li> <li>Tool-specific sandboxing and tool state management</li> <li>Domain-specific tool set tailored to software engineering and security tasks</li> </ul>"},{"location":"#hierarchical-memory-management","title":"Hierarchical Memory Management","text":"<ul> <li>Short-term memory: graph-based short-term memory</li> <li>Long-term memory: a graph managed by Neo4j and stored in a separate database</li> <li>Memory agent: equipped with memory read and write tools</li> </ul>"},{"location":"#documentation-index","title":"Documentation Index","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Introduction - What is OpenSage?</li> <li>Getting Started - Environment setup and installation</li> <li>Project Structure - Project structure overview</li> </ul>"},{"location":"#entry-points","title":"Entry Points","text":"<ul> <li>Entry Points - Overview of entry points</li> <li>OpenSage Web Entry - Interactive web UI workflow</li> <li>Evaluation Entry - Batch evaluation workflow</li> </ul>"},{"location":"#core-topics","title":"Core Topics","text":"<ul> <li>Core Components - Core components explained</li> </ul>"},{"location":"#development-guides","title":"Development Guides","text":"<ul> <li>Development Guides - Development guide overview</li> <li>Adding Tools - How to add new tools</li> <li>Sandboxes - Sandbox backends and how to add new sandboxes</li> <li>Adding a Evaluation Benchmark - How to add evaluation benchmarks</li> </ul>"},{"location":"#practices","title":"Practices","text":"<ul> <li>Best Practices - Best practices</li> <li>Tools - Tool types and patterns</li> <li>Testing Debugging - Testing and debugging</li> </ul>"},{"location":"#reference","title":"Reference","text":"<ul> <li>Contributing - Contributing guidelines</li> </ul> <p>Check the GitHub repository for the latest code</p>"},{"location":"Adding-Evaluations/","title":"Adding a Evaluation Benchmark","text":""},{"location":"Adding-Evaluations/#overview","title":"Overview","text":"<p>Evaluations are used to benchmark agent performance on specific tasks. The evaluation system in OpenSage is built on top of the base <code>Evaluation</code> class, which provides a complete framework for running benchmarks, managing sandboxes, collecting outputs, and generating metrics.</p>"},{"location":"Adding-Evaluations/#entry-points","title":"Entry Points","text":"<p>The <code>Evaluation</code> class provides multiple entry points for running evaluations, each suited for different use cases:</p>"},{"location":"Adding-Evaluations/#1-generate-multiprocessing-mode-default","title":"1. <code>generate()</code> - Multiprocessing Mode (Default)","text":"<ul> <li>Uses <code>ProcessPoolExecutor</code> for true parallelism</li> <li>Each sample runs in a separate process</li> <li>Best for production runs with maximum parallelism</li> <li>Bypasses Python's GIL for true concurrent execution</li> </ul>"},{"location":"Adding-Evaluations/#2-generate_threaded-multithreading-mode","title":"2. <code>generate_threaded()</code> - Multithreading Mode","text":"<ul> <li>Uses <code>ThreadPoolExecutor</code> for parallel execution</li> <li>Each sample runs in a separate thread</li> <li>Useful when multiprocessing has serialization issues</li> <li>Shares memory across threads</li> </ul>"},{"location":"Adding-Evaluations/#3-generate_single_thread-single-threaded-mode","title":"3. <code>generate_single_thread()</code> - Single-Threaded Mode","text":"<ul> <li>Sequential execution in a single thread</li> <li>Best for debugging and development</li> <li>Easiest to debug with step-by-step execution</li> </ul>"},{"location":"Adding-Evaluations/#4-run-auto-select-mode","title":"4. <code>run()</code> - Auto-Select Mode","text":"<ul> <li>Automatically selects execution mode based on <code>use_multiprocessing</code> flag</li> <li>If <code>use_multiprocessing=True</code>: calls <code>generate()</code> (multiprocessing)</li> <li>If <code>use_multiprocessing=False</code>: calls <code>generate_threaded()</code> (multithreading)</li> <li>Calls <code>evaluate()</code> after generation completes</li> <li>Recommended for most use cases</li> </ul>"},{"location":"Adding-Evaluations/#5-run_debug-debug-mode","title":"5. <code>run_debug()</code> - Debug Mode","text":"<ul> <li>Calls <code>generate_single_thread()</code> followed by <code>evaluate()</code></li> <li>Best for debugging and development</li> <li>Slower but easier to debug</li> </ul>"},{"location":"Adding-Evaluations/#usage-example","title":"Usage Example","text":"<p>Evaluations use Python Fire for command-line interface. You can run evaluations in several ways:</p> <p>Using command-line (recommended):</p> <pre><code># Option 1: Auto-select mode (uses generate() or generate_threaded() based on use_multiprocessing)\npython -m opensage.evaluations.my_benchmark.my_evaluation \\\n  --dataset_path=\"org/dataset\" \\\n  --agent_dir=\"examples/agents/my_agent\" \\\n  --max_workers=6 \\\n  --use_multiprocessing=true \\\n  run\n\n# Option 2: Explicit multiprocessing mode\npython -m opensage.evaluations.my_benchmark.my_evaluation \\\n  --dataset_path=\"org/dataset\" \\\n  --agent_dir=\"examples/agents/my_agent\" \\\n  generate\n\n# Option 3: Multithreading mode\npython -m opensage.evaluations.my_benchmark.my_evaluation \\\n  --dataset_path=\"org/dataset\" \\\n  --agent_dir=\"examples/agents/my_agent\" \\\n  generate_threaded\n\n# Option 4: Single-threaded debugging mode\npython -m opensage.evaluations.my_benchmark.my_evaluation \\\n  --dataset_path=\"org/dataset\" \\\n  --agent_dir=\"examples/agents/my_agent\" \\\n  run_debug\n\n# Or using direct file path\npython src/opensage/evaluations/my_benchmark/my_evaluation.py \\\n  --dataset_path=\"org/dataset\" \\\n  --agent_dir=\"examples/agents/my_agent\" \\\n  run\n</code></pre> <p>Using Python API:</p> <pre><code>from opensage.evaluations import MyEvaluation\n\n# Create evaluation instance\neval = MyEvaluation(\n    dataset_path=\"org/dataset\",\n    agent_dir=\"examples/agents/my_agent\",\n    max_workers=6,\n    use_multiprocessing=True,\n)\n\n# Option 1: Auto-select mode (recommended)\neval.run()\n\n# Option 2: Explicit multiprocessing\neval.generate()\n\n# Option 3: Multithreading\neval.generate_threaded()\n\n# Option 4: Single-threaded debugging\neval.run_debug()\n</code></pre>"},{"location":"Adding-Evaluations/#steps-to-create-a-new-evaluation","title":"Steps to Create a New Evaluation","text":""},{"location":"Adding-Evaluations/#1-create-evaluation-module","title":"1. Create Evaluation Module","text":"<p>Create a new directory under <code>src/opensage/evaluations/</code> with your benchmark name:</p> <pre><code>src/opensage/evaluations/\n\u2514\u2500\u2500 my_benchmark/\n    \u251c\u2500\u2500 __init__.py\n    \u2514\u2500\u2500 my_evaluation.py\n</code></pre>"},{"location":"Adding-Evaluations/#2-implement-evaluation-class","title":"2. Implement Evaluation Class","text":"<p>Create a class that inherits from <code>Evaluation</code> and implements required abstract methods:</p> <pre><code>from __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\nfrom opensage.evaluations import Evaluation, EvaluationTask\n\n@dataclass\nclass MyEvaluation(Evaluation):\n    \"\"\"Custom evaluation benchmark.\n\n    This class is automatically registered by name (lowercase).\n    You can retrieve it later using: get_evaluation_class(\"myevaluation\")\n    \"\"\"\n\n    # Required fields from parent class\n    dataset_path: str = \"org/dataset_name\"  # HuggingFace dataset or local path\n    agent_dir: str = \"examples/agents/my_agent\"  # Directory containing agent.py\n\n    # Optional configuration overrides\n    max_llm_calls: int = 100\n    max_workers: int = 6\n    use_multiprocessing: bool = True\n    run_until_explicit_finish: bool = True\n    use_cache: bool = True\n\n    # Custom fields for your benchmark\n    custom_param: str = \"default_value\"\n\n    # Implement required abstract methods\n    def _get_sample_id(self, sample: dict) -&gt; str:\n        \"\"\"Extract unique task ID from sample.\n\n        This ID is used for:\n        - Output directory naming\n        - Task identification in logs\n        - Result tracking\n        \"\"\"\n        return sample[\"task_id\"]  # or sample.get(\"id\"), etc.\n\n    def _get_user_msg_first(self, sample: dict) -&gt; str:\n        \"\"\"Extract the initial prompt/message to send to agent.\n\n        This is the first message that will trigger agent execution.\n        \"\"\"\n        return sample[\"prompt\"]  # or sample.get(\"question\"), etc.\n\n    # Optional: Override methods for custom behavior\n    def _get_dataset(self) -&gt; datasets.Dataset:\n        \"\"\"Load dataset with custom filtering or preprocessing.\"\"\"\n        dataset = super()._get_dataset()\n        # Add custom filtering logic if needed\n        # dataset = dataset.filter(lambda x: x[\"difficulty\"] == \"hard\")\n        return dataset\n\n    def _create_task(self, sample: dict) -&gt; EvaluationTask:\n        \"\"\"Create custom task with additional fields if needed.\"\"\"\n        task = super()._create_task(sample)\n        # Add custom fields to task if needed\n        return task\n\n    def _get_input_data_path(self, sample: dict) -&gt; str:\n        \"\"\"Specify input data directory for this sample.\"\"\"\n        task_id = self._get_sample_id(sample)\n        return str(Path(self.input_data_path) / task_id) if self.input_data_path else \"\"\n\n    def _get_cache_dir(self, sample: dict) -&gt; str:\n        \"\"\"Specify cache directory for sandbox state.\"\"\"\n        task_id = self._get_sample_id(sample)\n        return str(Path(self.cache_dir) / task_id) if self.cache_dir else \"\"\n\n    def _get_output_dir_in_sandbox(self, sample: dict) -&gt; str | tuple | None:\n        \"\"\"Specify which sandbox directories to export after execution.\"\"\"\n        return \"/output\"  # or (\"/output1\", \"/output2\") for multiple dirs\n\n    def customized_modify_and_save_results(\n        self,\n        *,\n        results: list | None,\n        failed_samples: list[str] | None,\n        mode: str,\n    ) -&gt; None:\n        \"\"\"Post-process and save aggregated results after all samples complete.\n\n        Args:\n            results: List of successful sample outputs\n            failed_samples: List of task IDs that failed\n            mode: Execution mode (\"multiprocess\", \"threaded\", or \"single_thread\")\n        \"\"\"\n        # Calculate metrics, save summary, etc.\n        pass\n\n    def evaluate(self) -&gt; None:\n        \"\"\"Analyze collected results and generate final metrics.\n\n        This is called after generate() completes. Implement your\n        evaluation logic here (accuracy, pass rate, etc.).\n        \"\"\"\n        # Load results from output_dir\n        # Calculate metrics\n        # Save evaluation report\n        pass\n</code></pre>"},{"location":"Adding-Evaluations/#3-configuration-template","title":"3. Configuration Template","text":"<p>Create a configuration template in <code>src/opensage/evaluations/configs/</code>:</p> <pre><code># src/opensage/evaluations/configs/my_benchmark_config.toml\n[llm]\nmodel_name = \"gemini-2.0-flash-exp\"\ntemperature = 0.7\n\n[sandbox]\n[sandbox.main]\ntype = \"docker\"\nimage = \"python:3.11\"\nworking_dir = \"/workspace\"\n\n# Template variables can be used:\n# ${TASK_NAME} - Replaced with actual task ID\n# ${PROJECT_RELATIVE_SHARED_DATA_PATH} - Replaced with data path\n</code></pre>"},{"location":"Adding-Evaluations/#4-registration","title":"4. Registration","text":"<p>The evaluation class is automatically registered when imported. The registration name is the lowercase class name.</p> <p>Example: - Class name: <code>MyEvaluation</code> \u2192 Registered as: <code>\"myevaluation\"</code> - Retrieve with: <code>get_evaluation_class(\"myevaluation\")</code></p>"},{"location":"Adding-Evaluations/#5-running-the-evaluation","title":"5. Running the Evaluation","text":"<p>Since evaluations use Python Fire, you can run them from command-line:</p> <pre><code># Run with auto-select mode (recommended)\npython -m opensage.evaluations.my_benchmark.my_evaluation \\\n  --dataset_path=\"org/dataset\" \\\n  --agent_dir=\"examples/agents/my_agent\" \\\n  --max_workers=6 \\\n  --output_dir=\"results/my_benchmark\" \\\n  run\n\n# Or for debugging (single-threaded)\npython -m opensage.evaluations.my_benchmark.my_evaluation \\\n  --dataset_path=\"org/dataset\" \\\n  --agent_dir=\"examples/agents/my_agent\" \\\n  run_debug\n\n# Or directly specify execution method\npython -m opensage.evaluations.my_benchmark.my_evaluation \\\n  --dataset_path=\"org/dataset\" \\\n  --agent_dir=\"examples/agents/my_agent\" \\\n  generate  # or generate_threaded, generate_single_thread\n</code></pre> <p>Or programmatically:</p> <pre><code>from opensage.evaluations import MyEvaluation\n\n# Create and run\neval = MyEvaluation(\n    dataset_path=\"org/dataset\",\n    agent_dir=\"examples/agents/my_agent\",\n    output_dir=\"results/my_benchmark\",  # Optional, auto-generated if not provided\n    max_workers=6,\n)\n\n# Run evaluation\neval.run()  # or eval.run_debug() for debugging\n</code></pre>"},{"location":"Adding-Evaluations/#evaluation-lifecycle","title":"Evaluation Lifecycle","text":"<p>Each evaluation sample goes through the following lifecycle:</p> <ol> <li>Task Creation (<code>_create_task()</code>)</li> <li>Convert dataset sample to <code>EvaluationTask</code></li> <li> <p>Extract task ID, prompt, paths, etc.</p> </li> <li> <p>Environment Preparation (<code>_prepare_environment()</code>)</p> </li> <li>Initialize OpenSage session</li> <li>Load/launch sandboxes</li> <li>Set up Neo4j (if enabled)</li> <li> <p>Load cached sandbox states (if <code>use_cache=True</code>)</p> </li> <li> <p>Agent Preparation (<code>_prepare_agent()</code>)</p> </li> <li>Load <code>mk_agent</code> function from <code>agent_dir</code></li> <li>Create agent instance</li> <li> <p>Configure model (if <code>use_config_model=True</code>)</p> </li> <li> <p>Agent Execution (<code>_run_agent()</code>)</p> </li> <li>Send prompt to agent</li> <li>Run agent with configured limits</li> <li>Track LLM calls, costs, etc.</li> <li> <p>Handle <code>run_until_explicit_finish</code> loop</p> </li> <li> <p>Output Collection (<code>_collect_outputs()</code>)</p> </li> <li>Export sandbox outputs (if <code>output_dir_in_sandbox</code> specified)</li> <li>Export Neo4j database</li> <li>Save session trace</li> <li> <p>Calculate cost information</p> </li> <li> <p>Cleanup</p> </li> <li>Clean up sandboxes</li> <li>Close sessions</li> <li>Save error information (if failed)</li> </ol>"},{"location":"Adding-Evaluations/#key-methods-to-override","title":"Key Methods to Override","text":""},{"location":"Adding-Evaluations/#required-abstract-methods","title":"Required Abstract Methods","text":"<ul> <li><code>_get_sample_id(sample: dict) -&gt; str</code>: Extract unique task ID</li> <li><code>_get_user_msg_first(sample: dict) -&gt; str</code>: Extract initial prompt</li> </ul>"},{"location":"Adding-Evaluations/#optional-methods-with-defaults","title":"Optional Methods (with Defaults)","text":"<ul> <li><code>_get_dataset() -&gt; datasets.Dataset</code>: Load and filter dataset</li> <li><code>_create_task(sample: dict) -&gt; EvaluationTask</code>: Create task instance</li> <li><code>_get_input_data_path(sample: dict) -&gt; str</code>: Input data directory</li> <li><code>_get_cache_dir(sample: dict) -&gt; str</code>: Cache directory</li> <li><code>_get_output_dir_in_sandbox(sample: dict) -&gt; str | tuple | None</code>: Output dirs to export</li> <li><code>_prepare_general_env() -&gt; None</code>: Setup shared across all samples</li> <li><code>_before_initialize_hooks(session, task) -&gt; None</code>: Hooks before sandbox init</li> <li><code>customized_modify_and_save_results(results, failed_samples, mode) -&gt; None</code>: Post-processing</li> <li><code>evaluate() -&gt; None</code>: Final evaluation and metrics</li> </ul>"},{"location":"Adding-Evaluations/#output-structure","title":"Output Structure","text":"<p>Each evaluation run creates an output directory with the following structure:</p> <pre><code>evals/\n\u2514\u2500\u2500 myevaluation/\n    \u2514\u2500\u2500 yymmdd_HHMMSS/\n        \u251c\u2500\u2500 evaluation_master.log       # Master log for entire run\n        \u251c\u2500\u2500 eval_params.json            # Evaluation parameters\n        \u251c\u2500\u2500 task_001/\n        \u2502   \u251c\u2500\u2500 execution_debug.log     # DEBUG-level log\n        \u2502   \u251c\u2500\u2500 execution_info.log      # INFO-level log\n        \u2502   \u251c\u2500\u2500 config_used.toml        # Config used for this task\n        \u2502   \u251c\u2500\u2500 cost_info.json          # Token usage and costs\n        \u2502   \u251c\u2500\u2500 session_trace.json      # Complete session events\n        \u2502   \u251c\u2500\u2500 session_trace.txt       # Human-readable trace\n        \u2502   \u251c\u2500\u2500 metadata.json           # Task metadata\n        \u2502   \u251c\u2500\u2500 sandbox_output/         # Exported from sandbox\n        \u2502   \u2514\u2500\u2500 neo4j_history/          # Neo4j database export\n        \u2514\u2500\u2500 task_002/\n            \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"Adding-Evaluations/#configuration-options","title":"Configuration Options","text":"<p>Key configuration options available in <code>Evaluation</code>:</p> Option Type Default Description <code>dataset_path</code> str Required HuggingFace dataset or local path <code>agent_dir</code> str Required Directory with <code>agent.py</code> <code>max_llm_calls</code> int 100 Maximum LLM calls per task <code>max_workers</code> int 6 Parallel workers <code>use_multiprocessing</code> bool True Use multiprocessing vs threading <code>use_cache</code> bool True Load/cache sandbox states <code>run_until_explicit_finish</code> bool True Keep running until task finished <code>use_config_model</code> bool False Use model from config file <code>llm_retry_count</code> int 3 Retries for LLM API calls <code>llm_retry_timeout</code> int 30 Timeout per LLM request (seconds) <code>log_level</code> str \"INFO\" Terminal log level"},{"location":"Adding-Evaluations/#examples","title":"Examples","text":"<p>See existing evaluations for reference:</p> <ul> <li><code>src/opensage/evaluations/cybergym/__init__.py</code> - Base class of evaluation</li> <li><code>src/opensage/evaluations/cybergym/cybergym_static.py</code> - Full-featured evaluation</li> <li><code>src/opensage/evaluations/mock_debug/mock_debug_evaluation.py</code> - Minimal example</li> <li><code>src/opensage/evaluations/secodeplt/vul_detection.py</code> - Another example</li> </ul>"},{"location":"Adding-Evaluations/#see-also","title":"See Also","text":"<ul> <li>Development Guides - Other development guides</li> <li>Testing Debugging - Testing evaluations</li> <li><code>src/opensage/evaluations/__init__.py</code> - Base Evaluation class implementation</li> </ul>"},{"location":"Adding-Tools/","title":"Adding a New Tool","text":""},{"location":"Adding-Tools/#overview","title":"Overview","text":"<p>OpenSage supports three tool types:</p> <ol> <li>Python tools: any callable function (docstring becomes the tool description)</li> <li>Agent Skills: filesystem-discovered bash/Python scripts described by <code>SKILL.md</code></li> <li>MCP toolsets: external services exposed via MCP (typically SSE)</li> </ol>"},{"location":"Adding-Tools/#tool-types","title":"Tool Types","text":""},{"location":"Adding-Tools/#1-python-tools","title":"1. Python Tools","text":"<p>Python tools are any callable functions you include in your agent\u2019s <code>tools=[...]</code>. The function signature becomes the tool schema, and the docstring is shown to the model as the tool description.</p> <p>Example:</p> <pre><code>def greet(name: str) -&gt; str:\n    \"\"\"Return a friendly greeting.\"\"\"\n    return f\"Hello, {name}!\"\n</code></pre> <p>Enable in your agent:</p> <pre><code>root_agent = OpenSageAgent(\n    name=\"my_agent\",\n    model=...,\n    instruction=\"...\",\n    tools=[greet],\n)\n</code></pre>"},{"location":"Adding-Tools/#2-agent-skills-bash-scripts","title":"2. Agent Skills (Bash Scripts)","text":"<p>Agent Skills are bash scripts organized in a structured directory format with metadata. They are automatically discovered and loaded by the framework.</p>"},{"location":"Adding-Tools/#3-mcp-toolsets","title":"3. MCP Toolsets","text":"<p>MCP (Model Context Protocol) toolsets provide integration with external services or tools running in separate containers, typically accessed via SSE (Server-Sent Events) connections.</p>"},{"location":"Adding-Tools/#creating-an-agent-skill","title":"Creating an Agent Skill","text":""},{"location":"Adding-Tools/#directory-structure","title":"Directory Structure","text":"<p>Create a skill directory under <code>src/opensage/bash_tools/</code>:</p> <pre><code>src/opensage/bash_tools/\n\u2514\u2500\u2500 category/\n    \u2514\u2500\u2500 tool-name/\n        \u251c\u2500\u2500 SKILL.md          # Tool metadata and documentation\n        \u2514\u2500\u2500 scripts/\n            \u2514\u2500\u2500 tool_script.sh # The actual bash script\n</code></pre> <p>Example structure: <pre><code>src/opensage/bash_tools/\n\u2514\u2500\u2500 retrieval/\n    \u2514\u2500\u2500 grep/\n        \u251c\u2500\u2500 SKILL.md\n        \u2514\u2500\u2500 scripts/\n            \u2514\u2500\u2500 grep.sh\n</code></pre></p>"},{"location":"Adding-Tools/#skillmd-format","title":"SKILL.md Format","text":"<p>The <code>SKILL.md</code> file contains YAML frontmatter and markdown documentation:</p> <pre><code>---\nname: tool-name\ndescription: Brief description of what the tool does\nshould_run_in_sandbox: main\n---\n\n# Tool Name\n\nDetailed description of the tool's functionality.\n\n## Usage\n\n```bash\nscripts/tool_script.sh arg1 arg2 --option value\n```\n\n## Parameters\n\n### param1 (required, positional position 0)\n\n**Type**: `str`\n\nDescription of the parameter.\n\n### param2 (optional, positional position 1)\n\n**Type**: `int`\n\nDescription of the parameter.\n\n### --option (optional, named parameter)\n\n**Type**: `str`\n\nDescription of the option.\n\n### --flag (optional, flag)\n\n**Type**: `bool` (default: `false`)\n\nDescription of the flag.\n\n## Return Value\n\nReturns a JSON object with results:\n\n```json\n{\n  \"success\": true,\n  \"result\": \"...\"\n}\n```\n\n## Requires Sandbox\n\nmain\n\n## Timeout\n\nDefault timeout: 60 seconds\n</code></pre> <p>Notes:</p> <ul> <li><code>should_run_in_sandbox</code> is required for executable Skills (a Skill folder   that contains <code>scripts/*.sh</code> or <code>scripts/*.py</code>).</li> <li>Use the Markdown section <code>## Requires Sandbox</code> for dependency sandboxes.   (Do not put <code>sandbox</code> / <code>sandboxes</code> fields in YAML frontmatter.)</li> </ul>"},{"location":"Adding-Tools/#parameter-types","title":"Parameter Types","text":"<ul> <li>Positional parameters: Specified with <code>positional position N</code> in the parameter description</li> <li>Named parameters: Use <code>--param_name value</code> format</li> <li>Boolean flags: Use <code>--flag</code> (no value needed)</li> </ul>"},{"location":"Adding-Tools/#bash-script-implementation","title":"Bash Script Implementation","text":"<p>The bash script should:</p> <ol> <li>Accept command-line arguments (positional and named)</li> <li>Return JSON output for structured results</li> <li>Use proper exit codes (0 for success, non-zero for errors)</li> </ol> <p>Example script:</p> <pre><code>#!/bin/bash\n\n# tool_script.sh - Tool description\n# Usage: ./tool_script.sh param1 param2 --option value\n\nif [ -z \"$1\" ]; then\n    echo '{\"error\": \"Missing required parameter\"}'\n    exit 1\nfi\n\nPARAM1=\"$1\"\nPARAM2=\"${2:-default}\"\n\n# Process --option if provided\nOPTION=\"\"\nwhile [[ $# -gt 0 ]]; do\n    case $1 in\n        --option)\n            OPTION=\"$2\"\n            shift 2\n            ;;\n        *)\n            shift\n            ;;\n    esac\ndone\n\n# Tool logic here\nRESULT=$(some_command \"$PARAM1\" \"$PARAM2\")\n\n# Return JSON\necho \"{\\\"success\\\": true, \\\"result\\\": \\\"$RESULT\\\"}\"\n</code></pre>"},{"location":"Adding-Tools/#sandbox-requirements","title":"Sandbox Requirements","text":"<p>Specify required sandbox types in the <code>## Requires Sandbox</code> section:</p> <pre><code>## Requires Sandbox\n\nmain\n</code></pre> <p>Or for multiple sandboxes:</p> <pre><code>## Requires Sandbox\n\nmain, fuzz\n</code></pre>"},{"location":"Adding-Tools/#automatic-discovery","title":"Automatic Discovery","text":"<p>Tools are automatically discovered from: - <code>src/opensage/bash_tools/</code> (built-in tools) - <code>~/.local/plugins/opensage/tools/</code> (user plugins)</p> <p>The framework scans these directories for <code>SKILL.md</code> files and loads them automatically.</p>"},{"location":"Adding-Tools/#enabled_skills-which-skills-get-loaded","title":"enabled_skills (which skills get loaded)","text":"<p>Agents can restrict which skills are available by setting <code>enabled_skills</code>:</p> <ul> <li><code>None</code>: load no skills</li> <li><code>\"all\"</code> / <code>[\"all\"]</code>: load only top-level skills (<code>&lt;root&gt;/*/SKILL.md</code>)</li> <li><code>List[str]</code>: treat each entry as a prefix allowlist under the skill root   (e.g. <code>\"fuzz\"</code> loads all skills under <code>fuzz/</code>; <code>\"fuzz/run-fuzzing-campaign\"</code> loads   just that subtree)</li> </ul>"},{"location":"Adding-Tools/#per-skill-dependency-installers-depsinstallsh","title":"Per-skill dependency installers (deps/install.sh)","text":"<p>If a skill needs extra dependencies inside a sandbox, it can provide an installer:</p> <ul> <li><code>deps/&lt;sandbox_type&gt;/install.sh</code> (sandbox-specific), and/or</li> <li><code>deps/install.sh</code> (generic)</li> </ul> <p>To control which sandbox should run the installer, add YAML frontmatter to <code>SKILL.md</code>:</p> <pre><code>---\nshould_run_in_sandbox: main\n---\n</code></pre> <p>Installers are run during sandbox initialization (best-effort) and are only run once per session (subsequent runs are skipped via a marker under <code>/shared</code>).</p>"},{"location":"Adding-Tools/#creating-an-mcp-toolset","title":"Creating an MCP Toolset","text":"<p>MCP toolsets are created via Python functions that return <code>MCPToolset</code> instances:</p> <pre><code># src/opensage/toolbox/category/get_toolset.py\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset, SseConnectionParams\nfrom opensage.toolbox.decorators import requires_sandbox, safe_tool_execution\nfrom opensage.utils.agent_utils import get_mcp_url_from_session_id\n\n@safe_tool_execution\n@requires_sandbox(\"gdb_mcp\")\ndef get_toolset(session_id: str) -&gt; MCPToolset:\n    \"\"\"Create MCPToolset with GDB MCP server running in Docker container.\n\n    Args:\n        session_id: Shared session ID for session-based management\n\n    Returns:\n        MCPToolset connected to GDB MCP server\n    \"\"\"\n    url = get_mcp_url_from_session_id(\"gdb_mcp\", session_id)\n    mcp_toolset = MCPToolset(connection_params=SseConnectionParams(url=url))\n    return mcp_toolset\n</code></pre> <p>The function should: - Use <code>@safe_tool_execution</code> decorator - Use <code>@requires_sandbox</code> to specify required sandbox types - Return an <code>MCPToolset</code> instance - Be registered in the agent's tools list</p>"},{"location":"Adding-Tools/#tool-registration","title":"Tool Registration","text":""},{"location":"Adding-Tools/#for-python-tools","title":"For Python Tools","text":"<p>Add the callable directly to your agent\u2019s <code>tools</code> list.</p>"},{"location":"Adding-Tools/#for-agent-skills","title":"For Agent Skills","text":"<p>Agent Skills are automatically discovered and registered. No manual registration needed.</p>"},{"location":"Adding-Tools/#for-mcp-toolsets","title":"For MCP Toolsets","text":"<p>Add the toolset getter function to your agent's tools:</p> <pre><code>from opensage.toolbox.category.get_toolset import get_toolset\n\nagent = Agent(\n    name=\"my_agent\",\n    tools=[get_toolset, ...],  # Add the getter function\n    ...\n)\n</code></pre>"},{"location":"Adding-Tools/#best-practices","title":"Best Practices","text":"<ol> <li>Use bash scripts for container operations: Prefer bash scripts for tools that interact with sandbox containers</li> <li>Return JSON: Always return structured JSON from bash scripts for easy parsing</li> <li>Document thoroughly: Include clear parameter descriptions and usage examples in <code>SKILL.md</code></li> <li>Handle errors gracefully: Use proper exit codes and error messages</li> <li>Specify sandbox requirements: Always document which sandboxes are required</li> <li>Use MCP for external services: Use MCP toolsets for tools that run in separate containers or services</li> </ol>"},{"location":"Adding-Tools/#see-also","title":"See Also","text":"<ul> <li>Tools - Tool types and patterns</li> <li>Best Practices - Best practices for tools</li> </ul>"},{"location":"Adding-a-New-Sandbox-Backend/","title":"Adding a new sandbox backend","text":""},{"location":"Adding-a-New-Sandbox-Backend/#overview","title":"Overview","text":"<p>A sandbox backend defines where/how sandboxes run (local Docker, remote Docker, Kubernetes, local/no-container, etc.). In this repo, backends are implemented as <code>BaseSandbox</code> subclasses and selected by <code>sandbox.backend</code>.</p> <p>This guide covers adding a new backend (not a new sandbox type).</p>"},{"location":"Adding-a-New-Sandbox-Backend/#steps","title":"Steps","text":""},{"location":"Adding-a-New-Sandbox-Backend/#1-implement-a-backend-class","title":"1) Implement a backend class","text":"<p>Create a new backend implementation under:</p> <ul> <li><code>OpenSage/src/opensage/sandbox/</code></li> </ul> <p>Backends are <code>BaseSandbox</code> subclasses (see <code>base_sandbox.py</code>) such as:</p> <ul> <li><code>native_docker_sandbox.py</code></li> <li><code>remote_docker_sandbox.py</code></li> <li><code>k8s_sandbox.py</code></li> <li><code>local_sandbox.py</code></li> </ul>"},{"location":"Adding-a-New-Sandbox-Backend/#2-register-the-backend","title":"2) Register the backend","text":"<p>Register your backend in:</p> <ul> <li><code>OpenSage/src/opensage/sandbox/factory.py</code> (<code>SANDBOX_BACKENDS</code>)</li> </ul> <p>Example (conceptually):</p> <pre><code>SANDBOX_BACKENDS[\"mybackend\"] = MyBackendSandbox\n</code></pre>"},{"location":"Adding-a-New-Sandbox-Backend/#3-optional-support-config-injection","title":"3) (Optional) Support config injection","text":"<p>If your backend needs configuration injected at runtime (similar to the remote docker backend), implement a <code>set_config(...)</code> classmethod and have the factory call it (see <code>get_backend_class(...)</code> in <code>factory.py</code>).</p>"},{"location":"Adding-a-New-Sandbox-Backend/#4-use-the-backend-in-config","title":"4) Use the backend in config","text":"<pre><code>[sandbox]\nbackend = \"mybackend\"\n</code></pre>"},{"location":"Adding-a-New-Sandbox-Backend/#tips","title":"Tips","text":"<ul> <li>Keep backend responsibilities focused on container/runtime management.</li> <li>Put \u201cwhat to install/configure\u201d in initializers (sandbox types), not in the   backend.</li> </ul>"},{"location":"Adding-a-Sandbox/","title":"Adding a sandbox","text":""},{"location":"Adding-a-Sandbox/#overview","title":"Overview","text":"<p>In this project, a \u201csandbox\u201d is created by combining:</p> <ul> <li>A sandbox backend (where/how the environment runs), and</li> <li>A sandbox initializer (what gets installed/configured in that environment).</li> </ul> <p>This guide covers adding a new sandbox type by implementing and registering a sandbox initializer.</p>"},{"location":"Adding-a-Sandbox/#steps","title":"Steps","text":""},{"location":"Adding-a-Sandbox/#1-create-an-initializer","title":"1) Create an initializer","text":"<p>Add a new initializer under:</p> <ul> <li><code>OpenSage/src/opensage/sandbox/initializers/</code></li> </ul> <p>Implement the <code>SandboxInitializer</code> interface from <code>OpenSage/src/opensage/sandbox/initializers/base.py</code>.</p>"},{"location":"Adding-a-Sandbox/#2-register-the-initializer","title":"2) Register the initializer","text":"<p>Register your initializer in the initializer registry:</p> <ul> <li><code>OpenSage/src/opensage/sandbox/factory.py</code> (<code>SANDBOX_INITIALIZERS</code>)</li> </ul> <p>This makes the sandbox type discoverable by name (e.g. <code>\"my_sandbox\"</code>).</p>"},{"location":"Adding-a-Sandbox/#3-add-configuration","title":"3) Add configuration","text":"<p>Add any required config fields to:</p> <ul> <li><code>OpenSage/src/opensage/config/config_dataclass.py</code></li> </ul> <p>and update the default config template (if you ship one) under:</p> <ul> <li><code>OpenSage/src/opensage/templates/configs/</code></li> </ul>"},{"location":"Adding-a-Sandbox/#4-configure-your-sandbox-in-toml","title":"4) Configure your sandbox in TOML","text":"<p>Example:</p> <pre><code>[sandbox.sandboxes.my_sandbox]\nimage = \"my_image:tag\"\n</code></pre>"},{"location":"Adding-a-Sandbox/#python-dependencies-in-sandbox-images","title":"Python dependencies in sandbox images","text":"<p>If your initializer or tools need Python packages, install them in the sandbox Docker image (not at runtime inside a running container).</p> <p>Recommended pattern:</p> <ol> <li>Install <code>uv</code> in the Dockerfile:</li> </ol> <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre> <ol> <li>Create a venv under <code>/app</code>:</li> </ol> <pre><code>uv venv --python 3.12\n</code></pre> <ol> <li>Install Python deps into the venv:</li> </ol> <pre><code>uv pip install &lt;deps...&gt;\n</code></pre> <p>Note: sandbox command execution is non-persistent (each command is a fresh process). Do not rely on <code>source /app/.venv/bin/activate</code> carrying over between commands. Prefer <code>/app/.venv/bin/python ...</code>.</p>"},{"location":"Adding-a-Sandbox/#example","title":"Example","text":"<pre><code>from opensage.sandbox.initializers.base import SandboxInitializer\n\n\nclass MySandboxInitializer(SandboxInitializer):\n  async def async_initialize(self) -&gt; None:\n    pass\n</code></pre>"},{"location":"Adding-a-Sandbox/#initialization-flow","title":"Initialization flow","text":"<ol> <li>Sandbox container is created</li> <li><code>async_initialize()</code> is called</li> <li>Resources are set up</li> <li>Sandbox is ready for use</li> </ol>"},{"location":"Adding-a-Sandbox/#skill-dependency-installers","title":"Skill dependency installers","text":"<p>Skills under <code>bash_tools/</code> can ship optional dependency installers:</p> <ul> <li><code>deps/&lt;sandbox_type&gt;/install.sh</code> (sandbox-specific), and/or</li> <li><code>deps/install.sh</code> (generic)</li> </ul> <p>The execution location is declared in <code>SKILL.md</code> YAML frontmatter via <code>should_run_in_sandbox</code>. During sandbox initialization, enabled skill installers are executed best-effort and skipped on subsequent runs via a marker under <code>/shared</code>.</p>"},{"location":"Benchmarking/","title":"Benchmarking","text":"<p>This section covers how to evaluate OpenSage agents and measure performance across tasks.</p>"},{"location":"Benchmarking/#what-youll-find-here","title":"What you'll find here","text":"<ul> <li>How to run built-in evaluations (entry point + workflow)</li> <li>How to add a new evaluation/benchmark to the repo</li> <li>Recommended reporting and reproducibility practices</li> </ul>"},{"location":"Benchmarking/#entry-points","title":"Entry points","text":"<ul> <li>Evaluation Entry: Batch evaluation workflow and   lifecycle.</li> <li>Adding a Evaluation Benchmark: How to integrate a new benchmark.</li> </ul>"},{"location":"Best-Practices/","title":"Best Practices","text":""},{"location":"Best-Practices/#session-management","title":"Session Management","text":"<ul> <li>Always use <code>opensage.get_session()</code> instead of creating sessions directly</li> <li>Clean up sessions when done: <code>opensage.cleanup_session(session_id)</code></li> <li>Use unique session IDs for different runs</li> </ul>"},{"location":"Best-Practices/#agent-development","title":"Agent Development","text":"<ul> <li>Keep agents focused on single responsibilities</li> <li>Use sub-agents for complex workflows</li> <li>Leverage tool combos for related tool groups</li> <li>Document tool parameters and return values</li> </ul>"},{"location":"Best-Practices/#tool-development","title":"Tool Development","text":""},{"location":"Best-Practices/#python-tools","title":"Python Tools","text":"<ul> <li>Keep tool functions small and focused</li> <li>Write clear docstrings (the LLM uses them as tool descriptions)</li> <li>Prefer structured return values (dict / JSON-like) for complex outputs</li> </ul>"},{"location":"Best-Practices/#agent-skills-bash-scripts","title":"Agent Skills (Bash Scripts)","text":"<ul> <li>Create structured directory with <code>SKILL.md</code> and <code>scripts/</code> subdirectory</li> <li>Document all parameters in <code>SKILL.md</code> with types and descriptions</li> <li>Set <code>should_run_in_sandbox</code> in <code>SKILL.md</code> YAML frontmatter for executable skills</li> <li>Specify sandbox requirements in <code>## Requires Sandbox</code> section</li> <li>Return JSON output for structured results</li> <li>Use proper exit codes (0 for success, non-zero for errors)</li> <li>Handle errors gracefully with informative JSON error messages</li> <li>Use positional and named parameters appropriately</li> <li>Set appropriate timeout values</li> </ul>"},{"location":"Best-Practices/#mcp-toolsets","title":"MCP Toolsets","text":"<ul> <li>Use <code>@safe_tool_execution</code> decorator</li> <li>Use <code>@requires_sandbox</code> to specify required sandbox types</li> <li>Return <code>MCPToolset</code> instances from getter functions</li> <li>Document connection parameters and usage</li> </ul>"},{"location":"Best-Practices/#configuration","title":"Configuration","text":"<ul> <li>Use template variables for environment-specific values</li> <li>Document configuration options</li> <li>Validate configuration in initialization</li> <li>Provide sensible defaults</li> </ul>"},{"location":"Best-Practices/#code-organization","title":"Code Organization","text":"<ul> <li>Follow existing module structure</li> <li>Use relative imports in source code</li> <li>Use absolute imports in tests</li> <li>Add docstrings to public APIs</li> </ul>"},{"location":"Best-Practices/#see-also","title":"See Also","text":"<ul> <li>Tools - Tool types and patterns</li> <li>Contributing - Contribution guidelines</li> </ul>"},{"location":"CHANGES/","title":"Documentation Changes","text":"<p>This file summarizes significant changes to the OpenSage documentation.</p>"},{"location":"CHANGES/#latest-updates","title":"Latest Updates","text":""},{"location":"CHANGES/#introductionmd-enhanced-selling-points-and-key-features","title":"Introduction.md - Enhanced selling points and key features","text":"<p>Date: Current update</p> <p>Changes Made:</p> <ol> <li>Expanded AI-Written Tools Section:</li> <li>Added detailed explanation of tools as \"first-class system entities\"</li> <li>Clarified the distinction between traditional tools and OpenSage's programmatic tools</li> <li> <p>Added design value propositions</p> </li> <li> <p>Enhanced Runtime Sub-Agents Section:</p> </li> <li>Added sub-agent positioning examples (Debugger, Retrieval, Fuzzer, Memory agents)</li> <li>Expanded on agent topology and dynamic graph concepts</li> <li> <p>Clarified agent ensemble capabilities</p> </li> <li> <p>Added System-Level Workflow Section (NEW - Planned Feature):</p> </li> <li>Rule-based execution model</li> <li>Graph-based scheduling</li> <li>Pub-sub event-driven coordination</li> <li> <p>Note: Feature is planned, placeholder documentation created</p> </li> <li> <p>Added Memory as Manageable System Resource Section (NEW - Planned Feature):</p> </li> <li>Layered memory model</li> <li>Graph-structured memory</li> <li>Memory agent concept</li> <li> <p>Note: Feature is planned, placeholder documentation created</p> </li> <li> <p>Enhanced Security-Focused Customization Section:</p> </li> <li>Renamed to \"Security-Focused System-Level Customization\"</li> <li>Added more detailed capabilities</li> <li> <p>Emphasized the system-level nature of customization</p> </li> <li> <p>Updated Key Features List:</p> </li> <li>Added planned features with notes</li> <li>Reorganized to match the selling points structure</li> </ol>"},{"location":"CHANGES/#new-files-created","title":"New Files Created","text":"<ol> <li>System-Workflow.md (removed):</li> <li>Placeholder documentation for planned system-level workflow feature</li> <li>Includes planned features: rule-based execution, graph-based scheduling, pub-sub events</li> <li> <p>Status: Planned/Under Development</p> </li> <li> <p>Memory-System.md (removed):</p> </li> <li>Placeholder documentation for planned memory system features</li> <li>Includes: layered memory, graph-structured memory, memory agent</li> <li> <p>Status: Planned/Under Development</p> </li> <li> <p>_Sidebar.md:</p> </li> <li>Updated to include links to new System-Workflow and Memory-System pages</li> </ol>"},{"location":"CHANGES/#previous-updates","title":"Previous Updates","text":""},{"location":"CHANGES/#project-name-update","title":"Project Name Update","text":"<p>All documentation was updated to reflect the project name OpenSage (Open Self-programming Agent Generation Engine).</p>"},{"location":"CLI-Reference/","title":"CLI Reference","text":"<p>This section documents the OpenSage command-line interface.</p>"},{"location":"CLI-Reference/#commands","title":"Commands","text":"<ul> <li><code>opensage</code>: Main CLI entry point</li> </ul> <p>See the generated reference pages:</p> <ul> <li>opensage</li> <li>opensage web</li> <li>opensage dependency-check</li> </ul>"},{"location":"CLI-Reference/#common-entry-points","title":"Common entry points","text":"<ul> <li>OpenSage Web Entry: Interactive development web UI</li> <li>Evaluation Entry: Batch evaluation entry point</li> </ul>"},{"location":"CLI-Reference/#auto-generation","title":"Auto-generation","text":"<p>The CLI reference pages above are generated at build time from <code>--help</code> output.</p>"},{"location":"Community/","title":"Community","text":"<p>This section covers how the project is developed and how contributors can get involved.</p>"},{"location":"Community/#contributing","title":"Contributing","text":"<ul> <li>See Contributing</li> </ul>"},{"location":"Community/#support-and-feedback","title":"Support and feedback","text":"<ul> <li>GitHub issues: Please open an issue in <code>OpenSage-ADK/OpenSage</code> with steps to   reproduce, expected behavior, and logs if applicable.</li> <li>Discord: Join the community chat at   discord.gg/zbKe5ue8xc.</li> </ul>"},{"location":"Configuration/","title":"Configuration Guide","text":"<p>This document describes the OpenSage configuration system, including all configuration fields, their purposes, and how to write configuration files.</p>"},{"location":"Configuration/#overview","title":"Overview","text":"<p>OpenSage uses TOML (Tom's Obvious, Minimal Language) format for configuration files. The configuration system supports:</p> <ul> <li>Template Variables: Use <code>${VAR_NAME}</code> syntax for reusable values</li> <li>Nested Sections: Organize related settings into logical groups</li> <li>Environment Variable Support: Template variables can reference environment variables</li> <li>Type Safety: Automatic conversion to Python dataclasses with type checking</li> </ul>"},{"location":"Configuration/#configuration-file-location","title":"Configuration File Location","text":"<p>Configuration files are loaded in the following order:</p> <ol> <li>Default Configuration: <code>src/opensage/templates/configs/default_config.toml</code> (used when no config is specified)</li> <li>Custom Configuration: Path specified via <code>config_path</code> parameter when creating a session</li> </ol>"},{"location":"Configuration/#configuration-structure","title":"Configuration Structure","text":"<p>The configuration is organized into several main sections:</p> <pre><code># Top-level template variables (optional)\nVARIABLE_NAME = \"value\"\n\n# Root-level fields\ntask_name = \"my_task\"\nsrc_dir_in_sandbox = \"/shared/code\"\ndefault_host = \"127.0.0.1\"\nauto_cleanup = true\n\n# Section-based configuration\n[neo4j]\n# Neo4j database configuration\n\n[sandbox]\n# Sandbox configuration\n\n[llm]\n# LLM model configuration\n\n[history]\n# History and tool response configuration\n\n[plugins]\n# Plugin configuration\n\n[agent_ensemble]\n# Agent ensemble configuration\n\n[build]\n# Build and execution configuration\n\n[mcp]\n# Model Context Protocol services configuration\n</code></pre>"},{"location":"Configuration/#template-variables","title":"Template Variables","text":"<p>OpenSage supports template variable expansion using <code>${VAR_NAME}</code> syntax.</p>"},{"location":"Configuration/#rules","title":"Rules:","text":"<ol> <li>Top-level UPPERCASE variables automatically become template variables</li> <li>Variables can be referenced anywhere using <code>${VAR_NAME}</code></li> <li>Variables are expanded recursively throughout the configuration</li> <li>Undefined variables cause an error at load time</li> </ol>"},{"location":"Configuration/#example","title":"Example:","text":"<pre><code># Define template variables (UPPERCASE)\nDEFAULT_IMAGE = \"ubuntu:20.04\"\nMAIN_MODEL = \"openai/gpt-4\"\nNEO4J_PASSWORD = \"mypassword123\"\n\n# Use template variables\n[sandbox.sandboxes.main]\nimage = \"${DEFAULT_IMAGE}\"\n\n[llm.model_configs.main]\nmodel_name = \"${MAIN_MODEL}\"\n\n[neo4j]\npassword = \"${NEO4J_PASSWORD}\"\n</code></pre>"},{"location":"Configuration/#configuration-sections","title":"Configuration Sections","text":""},{"location":"Configuration/#root-level-fields","title":"Root-Level Fields","text":"<p>These fields are defined at the top level of the configuration file:</p> Field Type Description Default <code>task_name</code> <code>string</code> Name identifier for the current task/session <code>None</code> <code>src_dir_in_sandbox</code> <code>string</code> Path to source code directory within sandbox containers <code>\"/shared/code\"</code> <code>agent_storage_path</code> <code>string</code> Path where dynamically created agents are stored <code>None</code> <code>default_host</code> <code>string</code> Default hostname for services (used by Neo4j and MCP services) <code>None</code> (falls back to <code>127.0.0.1</code>) <code>auto_cleanup</code> <code>boolean</code> Whether to automatically cleanup resources when session ends <code>true</code> <p>Example:</p> <pre><code>task_name = \"vulnerability_analysis\"\nsrc_dir_in_sandbox = \"/shared/code\"\nagent_storage_path = \"/tmp/agents\"\ndefault_host = \"localhost\"\nauto_cleanup = true\n</code></pre>"},{"location":"Configuration/#neo4j-configuration","title":"Neo4j Configuration","text":"<p>Configures the Neo4j graph database connection.</p> <p>Section: <code>[neo4j]</code></p>"},{"location":"Configuration/#sandbox-images-requirements-practical-notes","title":"Sandbox Images &amp; Requirements (Practical Notes)","text":"<p>Some sandboxes require Python tooling inside their Docker images. In the default configuration template (<code>src/opensage/templates/configs/default_config.toml</code>):</p> <ul> <li><code>sandbox.sandboxes.main</code></li> <li>Built from <code>src/opensage/templates/dockerfiles/main/Dockerfile</code></li> <li>Provides <code>python3</code> via <code>/app/.venv/bin/python</code></li> <li> <p>Installs Python package <code>neo4j</code> (used by <code>src/opensage/sandbox/initializers/main.py</code>)</p> </li> <li> <p><code>sandbox.sandboxes.joern</code></p> </li> <li>Built from <code>src/opensage/templates/dockerfiles/joern/Dockerfile</code></li> <li>Provides <code>python3</code> via <code>/app/.venv/bin/python</code></li> <li>Installs Python packages <code>httpx</code> and <code>websockets</code> (used by Joern query helper scripts)</li> </ul> <p>These images install Python deps using <code>uv</code> in the Dockerfile (create <code>/app/.venv</code> and run <code>uv pip install ...</code>), rather than at runtime inside a running container.</p> Field Type Description Default <code>user</code> <code>string</code> Neo4j username <code>None</code> <code>password</code> <code>string</code> Neo4j password <code>None</code> <code>bolt_port</code> <code>integer</code> Neo4j Bolt protocol port <code>7687</code> <code>neo4j_http_port</code> <code>integer</code> Neo4j HTTP port <code>7474</code> <p>Note: The <code>uri</code> property is dynamically constructed as <code>neo4j://{default_host}:{bolt_port}</code>. If <code>default_host</code> is not set, it defaults to <code>127.0.0.1</code>.</p> <p>Example:</p> <pre><code>[neo4j]\nuser = \"neo4j\"\npassword = \"callgraphn4j!\"\nbolt_port = 7687\nneo4j_http_port = 7474\n</code></pre>"},{"location":"Configuration/#sandbox-configuration","title":"Sandbox Configuration","text":"<p>Configures sandbox environments (Docker containers or Kubernetes pods).</p> <p>Section: <code>[sandbox]</code></p>"},{"location":"Configuration/#top-level-sandbox-settings","title":"Top-Level Sandbox Settings","text":"Field Type Description Default <code>default_image</code> <code>string</code> Default Docker image for sandboxes <code>None</code> <code>backend</code> <code>string</code> Sandbox backend type: <code>\"native\"</code> (Docker) or <code>\"k8s\"</code> (Kubernetes; under development) <code>\"native\"</code> <code>project_relative_shared_data_path</code> <code>string</code> Path relative to project root for shared data (will be mounted as <code>/shared</code> in containers) <code>None</code> <code>absolute_shared_data_path</code> <code>string</code> Absolute path for shared data <code>None</code> <code>tolerations</code> <code>list[dict]</code> Kubernetes tolerations applied to all pods (k8s; under development) <code>None</code>"},{"location":"Configuration/#per-sandbox-configuration","title":"Per-Sandbox Configuration","text":"<p>Each sandbox type is configured under <code>[sandbox.sandboxes.&lt;sandbox_type&gt;]</code>:</p> <p>Common Sandbox Types: - <code>main</code>: Primary analysis sandbox - <code>joern</code>: Joern static analysis sandbox - <code>codeql</code>: CodeQL analysis sandbox - <code>neo4j</code>: Neo4j database container - <code>gdb_mcp</code>: GDB debugger MCP service - <code>pdb_mcp</code>: PDB debugger MCP service - <code>fuzz</code>: Fuzzing environment</p> <p>Container Configuration Fields:</p> Field Type Description Default <code>image</code> <code>string</code> Docker image name/tag <code>None</code> <code>container_id</code> <code>string</code> Connect to existing container (instead of creating new) <code>None</code> <code>timeout</code> <code>integer</code> Container operation timeout in seconds <code>300</code> <code>project_relative_dockerfile_path</code> <code>string</code> Path to Dockerfile relative to project root <code>None</code> <code>absolute_dockerfile_path</code> <code>string</code> Absolute path to Dockerfile <code>None</code> <code>command</code> <code>string</code> Override container command (empty string = use Dockerfile default, <code>None</code> = use <code>bash</code>) <code>None</code> <code>platform</code> <code>string</code> Platform architecture (e.g., <code>\"linux/amd64\"</code>) <code>None</code> <code>network</code> <code>string</code> Docker network name <code>None</code> <code>privileged</code> <code>boolean</code> Run container in privileged mode <code>false</code> <code>security_opt</code> <code>list[string]</code> Security options <code>[]</code> <code>cap_add</code> <code>list[string]</code> Additional capabilities <code>[]</code> <code>gpus</code> <code>string</code> GPU allocation (e.g., <code>\"all\"</code> or <code>\"device=GPU-UUID\"</code>) <code>None</code> <code>shm_size</code> <code>string</code> Shared memory size (e.g., <code>\"2g\"</code>) <code>None</code> <code>mem_limit</code> <code>string</code> Memory limit (e.g., <code>\"4g\"</code>) <code>None</code> <code>cpus</code> <code>string</code> CPU limit (e.g., <code>\"2\"</code>) <code>None</code> <code>user</code> <code>string</code> User to run as (e.g., <code>\"1000:1000\"</code>) <code>None</code> <code>working_dir</code> <code>string</code> Working directory in container <code>None</code> <p>Build Configuration:</p> Field Type Description <code>build_args</code> <code>dict[string, string]</code> Docker build arguments <code>using_cached</code> <code>boolean</code> Whether to use cached image (internal flag) <p>Environment, Volumes, and Ports:</p> Field Type Description <code>environment</code> <code>dict[string, any]</code> Environment variables <code>volumes</code> <code>list[string]</code> Volume mounts in format <code>\"/host:/container:ro\"</code> <code>mounts</code> <code>list[string]</code> Docker mount specifications <code>ports</code> <code>dict[string, int\\|string]</code> Port mappings in format <code>{\"port/tcp\" = host_port}</code> <code>docker_args</code> <code>list[string]</code> Raw arguments passed through to Docker CLI <p>Extra Configuration:</p> Field Type Description <code>extra</code> <code>dict[string, any]</code> Additional custom configuration (e.g., <code>initializer_timeout_sec</code>) <p>Kubernetes-Specific Fields:</p> Field Type Description <code>pod_name</code> <code>string</code> Connect to existing Pod instead of creating new <code>container_name</code> <code>string</code> Name of container within the Pod <p>Example:</p> <pre><code>[sandbox]\nbackend = \"native\"\nproject_relative_shared_data_path = \"data/my_project.tar.gz\"\n\n[sandbox.sandboxes.main]\nimage = \"ubuntu:20.04\"\nproject_relative_dockerfile_path = \"dockerfiles/main/Dockerfile\"\ntimeout = 300\n\n[sandbox.sandboxes.main.build_args]\nBASE_IMAGE = \"ubuntu:20.04\"\n\n[sandbox.sandboxes.main.environment]\nPYTHONPATH = \"/shared/code\"\n\n[sandbox.sandboxes.main.ports]\n\"8080/tcp\" = 8080\n\n[sandbox.sandboxes.main.extra]\ninitializer_timeout_sec = 1800\n\n[sandbox.sandboxes.joern]\nimage = \"opensage/joern\"\nproject_relative_dockerfile_path = \"dockerfiles/joern/Dockerfile\"\ncommand = \"\"\n\n[sandbox.sandboxes.joern.environment]\nJAVA_OPTS = \"-Xmx16G -Xms4G\"\n\n[sandbox.sandboxes.joern.ports]\n\"8081/tcp\" = 18087\n</code></pre>"},{"location":"Configuration/#llm-configuration","title":"LLM Configuration","text":"<p>Configures language models used by agents.</p> <p>Section: <code>[llm]</code></p> <p>Models are configured under <code>[llm.model_configs.&lt;model_name&gt;]</code>:</p> <p>Common Model Names: - <code>main</code>: Primary model for agent reasoning - <code>summarize</code>: Model for summarization and context compression - <code>flag_claims</code>: Model for flag claims processing</p> <p>Model Configuration Fields:</p> Field Type Description Default <code>model_name</code> <code>string</code> Model identifier (e.g., <code>\"openai/gpt-4\"</code>, <code>\"anthropic/claude-3\"</code>) Required <code>temperature</code> <code>float</code> Sampling temperature (0.0-2.0) <code>None</code> <code>max_tokens</code> <code>integer</code> Maximum tokens in response <code>None</code> <code>rpm</code> <code>integer</code> Rate limit: requests per minute <code>None</code> <code>tpm</code> <code>integer</code> Rate limit: tokens per minute <code>None</code> <p>Example:</p> <pre><code>[llm]\n\n[llm.model_configs.main]\nmodel_name = \"openai/gpt-4\"\ntemperature = 0.7\nmax_tokens = 4096\nrpm = 60\ntpm = 60000\n\n[llm.model_configs.summarize]\nmodel_name = \"openai/gpt-3.5-turbo\"\ntemperature = 0.3\nmax_tokens = 2048\nrpm = 30\ntpm = 30000\n</code></pre>"},{"location":"Configuration/#history-configuration","title":"History Configuration","text":"<p>Configures tool response handling and event history management.</p> <p>Section: <code>[history]</code></p> Field Type Description Default <code>max_tool_response_length</code> <code>integer</code> Maximum length of a single tool response before special handling <code>10000</code> <code>enable_quota_countdown</code> <code>boolean</code> Show remaining LLM call quota after each tool response <code>false</code> <p>Events Compaction Configuration:</p> <p>Section: <code>[history.events_compaction]</code></p> Field Type Description Default <code>max_history_summary_length</code> <code>integer</code> Character budget threshold for triggering compaction <code>100000</code> <code>compaction_percent</code> <code>integer</code> Percentage of history to compress (0-100) <code>50</code> <p>Example:</p> <pre><code>[history]\nmax_tool_response_length = 10000\nenable_quota_countdown = true\n\n[history.events_compaction]\nmax_history_summary_length = 100000\ncompaction_percent = 50\n</code></pre>"},{"location":"Configuration/#plugins-configuration","title":"Plugins Configuration","text":"<p>Configures which plugins are enabled.</p> <p>Section: <code>[plugins]</code></p> Field Type Description Default <code>enabled</code> <code>list[string]</code> List of enabled plugin names <code>[]</code> <p>Common Plugins: - <code>history_summarizer_plugin</code>: Summarizes long conversation history - <code>tool_response_summarizer_plugin</code>: Summarizes long tool responses - <code>quota_after_tool_plugin</code>: Shows quota countdown after tools</p> <p>Example:</p> <pre><code>[plugins]\nenabled = [\n    \"history_summarizer_plugin\",\n    \"tool_response_summarizer_plugin\",\n    \"quota_after_tool_plugin\",\n]\n</code></pre>"},{"location":"Configuration/#agent-ensemble-configuration","title":"Agent Ensemble Configuration","text":"<p>Configures multi-agent ensemble execution.</p> <p>Section: <code>[agent_ensemble]</code></p> Field Type Description Default <code>thread_safe_tools</code> <code>list[string]</code> List of tool names that are thread-safe (can be called in parallel) <code>[]</code> <code>available_models_for_ensemble</code> <code>list[string]</code> or <code>string</code> List of model names available for ensemble (can be comma-separated string) <code>[]</code> <p>Example:</p> <pre><code>[agent_ensemble]\nthread_safe_tools = [\"google_search\", \"read_file\"]\navailable_models_for_ensemble = [\"openai/gpt-4\", \"anthropic/claude-3\"]\n</code></pre> <p>Or as comma-separated string:</p> <pre><code>[agent_ensemble]\nthread_safe_tools = [\"google_search\", \"read_file\"]\navailable_models_for_ensemble = \"openai/gpt-4,anthropic/claude-3\"\n</code></pre>"},{"location":"Configuration/#build-configuration","title":"Build Configuration","text":"<p>Configures build and execution commands for target programs.</p> <p>Section: <code>[build]</code></p> Field Type Description Default <code>poc_dir</code> <code>string</code> Directory path for proof-of-concept code <code>None</code> <code>compile_command</code> <code>string</code> Command to compile the target program <code>None</code> <code>run_command</code> <code>string</code> Command to run the target program <code>None</code> <code>target_type</code> <code>string</code> Type of target (e.g., <code>\"default\"</code>, <code>\"binary\"</code>) <code>None</code> <code>target_binary</code> <code>string</code> Path to target binary <code>None</code> <p>Example:</p> <pre><code>[build]\npoc_dir = \"/tmp/poc\"\ncompile_command = \"gcc -o target target.c\"\nrun_command = \"./target\"\ntarget_type = \"binary\"\ntarget_binary = \"/tmp/poc/target\"\n</code></pre>"},{"location":"Configuration/#mcp-configuration","title":"MCP Configuration","text":"<p>Configures Model Context Protocol (MCP) services.</p> <p>Section: <code>[mcp]</code></p> <p>MCP services are configured under <code>[mcp.services.&lt;service_name&gt;]</code>:</p> <p>Common Service Names: - <code>gdb_mcp</code>: GDB debugger MCP service - <code>pdb_mcp</code>: PDB debugger MCP service</p> <p>MCP Service Configuration Fields:</p> Field Type Description <code>sse_port</code> <code>integer</code> Server-Sent Events (SSE) server port <code>sse_host</code> <code>string</code> SSE server host (if <code>None</code>, uses <code>default_host</code> from root config) <p>Note: The <code>sse_host</code> property dynamically uses <code>default_host</code> from the root configuration if not explicitly set.</p> <p>Example:</p> <pre><code>[mcp]\n\n[mcp.services.gdb_mcp]\nsse_port = 1111\n\n[mcp.services.pdb_mcp]\nsse_port = 1112\nsse_host = \"localhost\"  # Optional, defaults to root config's default_host\n</code></pre>"},{"location":"Configuration/#complete-example","title":"Complete Example","text":"<p>Here's a complete configuration file example:</p> <pre><code># Template Variables\nDEFAULT_IMAGE = \"ubuntu:20.04\"\nMAIN_MODEL = \"openai/gpt-4\"\nNEO4J_PASSWORD = \"secure_password\"\nTASK_NAME = \"security_analysis\"\n\n# Root Configuration\ntask_name = \"${TASK_NAME}\"\nsrc_dir_in_sandbox = \"/shared/code\"\ndefault_host = \"localhost\"\nauto_cleanup = true\n\n# Neo4j Configuration\n[neo4j]\nuser = \"neo4j\"\npassword = \"${NEO4J_PASSWORD}\"\nbolt_port = 7687\nneo4j_http_port = 7474\n\n# Sandbox Configuration\n[sandbox]\nbackend = \"native\"\nproject_relative_shared_data_path = \"data/project.tar.gz\"\n\n[sandbox.sandboxes.main]\nimage = \"${DEFAULT_IMAGE}\"\nproject_relative_dockerfile_path = \"dockerfiles/main/Dockerfile\"\ntimeout = 300\n\n[sandbox.sandboxes.main.environment]\nPYTHONPATH = \"/shared/code\"\n\n[sandbox.sandboxes.joern]\nimage = \"opensage/joern\"\nproject_relative_dockerfile_path = \"dockerfiles/joern/Dockerfile\"\ncommand = \"\"\n\n[sandbox.sandboxes.joern.ports]\n\"8081/tcp\" = 18087\n\n# LLM Configuration\n[llm]\n\n[llm.model_configs.main]\nmodel_name = \"${MAIN_MODEL}\"\ntemperature = 0.7\nmax_tokens = 4096\n\n[llm.model_configs.summarize]\nmodel_name = \"${MAIN_MODEL}\"\ntemperature = 0.3\nmax_tokens = 2048\n\n# History Configuration\n[history]\nmax_tool_response_length = 10000\nenable_quota_countdown = true\n\n[history.events_compaction]\nmax_history_summary_length = 100000\ncompaction_percent = 50\n\n# Plugins Configuration\n[plugins]\nenabled = [\n    \"history_summarizer_plugin\",\n    \"tool_response_summarizer_plugin\",\n]\n\n# Agent Ensemble Configuration\n[agent_ensemble]\nthread_safe_tools = [\"google_search\"]\navailable_models_for_ensemble = \"${MAIN_MODEL}\"\n\n# Build Configuration\n[build]\ncompile_command = \"make\"\nrun_command = \"./target\"\n\n# MCP Configuration\n[mcp]\n\n[mcp.services.gdb_mcp]\nsse_port = 1111\n</code></pre>"},{"location":"Configuration/#loading-configuration-in-code","title":"Loading Configuration in Code","text":""},{"location":"Configuration/#using-default-configuration","title":"Using Default Configuration","text":"<pre><code>import opensage\n\n# Uses default config from src/opensage/templates/configs/default_config.toml\nsession = opensage.get_session(\"my_session\")\n</code></pre>"},{"location":"Configuration/#using-custom-configuration","title":"Using Custom Configuration","text":"<pre><code>import opensage\n\n# Load custom configuration file\nsession = opensage.get_session(\n    \"my_session\",\n    config_path=\"/path/to/my_config.toml\",\n)\n</code></pre>"},{"location":"Configuration/#accessing-configuration","title":"Accessing Configuration","text":"<pre><code># Access configuration through session\nconfig = session.config\n\n# Access specific sections\nneo4j_config = config.neo4j\nsandbox_config = config.sandbox\nllm_config = config.llm\n\n# Access nested configurations\nmain_sandbox = config.get_sandbox_config(\"main\")\nmain_model = config.get_llm_config(\"main\")\n</code></pre>"},{"location":"Configuration/#best-practices","title":"Best Practices","text":"<ol> <li>Use Template Variables: Define reusable values as UPPERCASE template variables at the top</li> <li>Organize by Section: Group related settings into logical sections</li> <li>Document Custom Fields: Add comments for non-standard or custom configuration</li> <li>Version Control: Keep configuration files in version control, but exclude sensitive values (passwords, API keys)</li> <li>Environment-Specific Configs: Create separate config files for development, testing, and production</li> <li>Validate Early: Test configuration files before deploying to catch errors early</li> </ol>"},{"location":"Configuration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"Configuration/#template-variable-not-found","title":"Template Variable Not Found","text":"<p>If you see <code>KeyError: Template variable 'VAR_NAME' not found</code>, ensure: - The variable is defined as an UPPERCASE top-level variable - The variable name matches exactly (case-sensitive) - There are no typos in <code>${VAR_NAME}</code> references</p>"},{"location":"Configuration/#configuration-not-loading","title":"Configuration Not Loading","text":"<ul> <li>Verify the TOML file syntax is correct</li> <li>Check file path is correct (use absolute paths if relative paths don't work)</li> <li>Ensure all required fields are present (check error messages)</li> </ul>"},{"location":"Configuration/#dynamic-host-resolution","title":"Dynamic Host Resolution","text":"<p>If <code>default_host</code> is not set, services like Neo4j and MCP will default to <code>127.0.0.1</code>. Set <code>default_host</code> at the root level for Kubernetes deployments or remote services.</p>"},{"location":"Configuration/#related-documentation","title":"Related Documentation","text":"<ul> <li>Getting Started - Initial setup guide</li> <li>Core Components - How configuration fits in the system</li> <li>Sandboxes - Sandbox backends and configuration guide</li> </ul>"},{"location":"Contributing/","title":"Contributing Guidelines","text":""},{"location":"Contributing/#code-style","title":"Code Style","text":"<ul> <li>Follow Google Python Style Guide</li> <li>Use <code>pyink</code> for formatting</li> <li>Use <code>isort</code> for import sorting</li> <li>Run <code>autoformat.sh</code> before committing</li> </ul>"},{"location":"Contributing/#commit-messages","title":"Commit Messages","text":"<p>Follow Conventional Commits format:</p> <pre><code>feat(component): Description\nfix(component): Description\nrefactor(component): Description\n</code></pre>"},{"location":"Contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Create feature branch</li> <li>Make changes with tests</li> <li>Run tests and linting</li> <li>Update documentation</li> <li>Submit PR with description</li> </ol>"},{"location":"Contributing/#see-also","title":"See Also","text":"<ul> <li>Best Practices - Development best practices</li> <li>Development Guides - How to extend the framework</li> </ul>"},{"location":"Core-Components/","title":"Core Components","text":"<p>OpenSage core components.</p>"},{"location":"Core-Components/#1-session","title":"1. Session","text":"<p>The central manager for all session-specific resources.</p> <p>Key Responsibilities:</p> <ul> <li>Configuration management (TOML loading, env overrides)</li> <li>Agent lifecycle (creation, persistence, cleanup)</li> <li>Sandbox management (Docker containers, resource isolation)</li> <li>Neo4j client management</li> <li>Agent ensemble coordination</li> </ul> <p>Key Files:</p> <ul> <li><code>opensage.session.session</code></li> <li><code>opensage.session.dynamic_agent_manager</code></li> <li><code>opensage.session.sandbox_manager</code></li> </ul>"},{"location":"Core-Components/#2-agent","title":"2. Agent","text":"<p>Extended ADK agent with security-focused features.</p> <p>Key Features:</p> <ul> <li>Dynamic tool loading from filesystem</li> <li>Integration with sandbox environments</li> <li>Tool combo support</li> <li>Session-aware tool execution</li> </ul> <p>Key Files:</p> <ul> <li>Agent implementation lives under the <code>opensage.agents</code> namespace.</li> </ul>"},{"location":"Core-Components/#3-sandbox-system","title":"3. Sandbox System","text":"<p>Isolated execution environments for security analysis.</p> <p>Sandbox Types:</p> <ul> <li><code>main</code>: Primary analysis sandbox</li> <li><code>joern</code>: Static analysis (CPG generation)</li> <li><code>codeql</code>: CodeQL analysis</li> <li><code>neo4j</code>: Graph database for CPG storage</li> <li><code>gdb_mcp</code>: Debugger integration</li> <li><code>fuzz</code>: Fuzzing environment</li> </ul> <p>Key Files:</p> <ul> <li><code>opensage.sandbox.base_sandbox</code></li> <li><code>opensage.sandbox.native_docker_sandbox</code></li> <li><code>opensage.sandbox.k8s_sandbox</code></li> <li><code>opensage.sandbox.initializers</code></li> </ul> <p>Docs:</p> <ul> <li>Sandbox System Guide</li> <li>Adding a sandbox</li> <li>Adding a new sandbox backend</li> </ul>"},{"location":"Core-Components/#4-configuration-system","title":"4. Configuration System","text":"<p>TOML-based configuration with template variable expansion.</p> <p>Key Files:</p> <ul> <li><code>opensage.config.config_dataclass</code></li> <li><code>opensage.templates.configs.default_config</code></li> </ul> <p>Docs:</p> <ul> <li>Configuration</li> </ul>"},{"location":"Core-Components/#5-tools","title":"5. Tools","text":"<p>Collection of security analysis tools.</p> <p>Tool Categories:</p> <ul> <li>Static Analysis: Joern, CodeQL queries</li> <li>Dynamic Analysis: Fuzzing, debugging</li> <li>Coverage: LLVM coverage tools</li> <li>Retrieval: Code search and symbol lookup</li> <li>Evaluation: PoC submission and validation</li> </ul> <p>Key Files:</p> <ul> <li><code>opensage.toolbox</code></li> </ul> <p>Docs:</p> <ul> <li>Tools</li> <li>Adding a New Tool</li> </ul>"},{"location":"Core-Components/#related-topics","title":"Related Topics","text":"<ul> <li>Adding a Evaluation Benchmark</li> <li>Development Guides - How to extend components</li> </ul>"},{"location":"Development-Guides/","title":"Development Guides","text":"<p>This section covers how to extend OpenSage with new functionality.</p>"},{"location":"Development-Guides/#guides","title":"Guides","text":"<ul> <li>Adding Tools - How to add new tools</li> <li>Sandboxes - Sandbox backends and how to add new sandbox types</li> <li>Adding a Evaluation Benchmark - How to add evaluation benchmarks</li> </ul>"},{"location":"Development-Guides/#extending-the-base-agent","title":"Extending the Base Agent","text":"<p>To add features to the base agent:</p> <ol> <li>Modify code under <code>src/opensage/agents/</code></li> <li>Ensure backward compatibility</li> <li>Add configuration options if needed</li> <li>Update documentation</li> </ol>"},{"location":"Development-Guides/#general-development-workflow","title":"General Development Workflow","text":"<ol> <li>Create feature branch</li> <li>Make changes with tests</li> <li>Run tests and linting</li> <li>Update documentation</li> <li>Submit PR</li> </ol>"},{"location":"Development-Guides/#see-also","title":"See Also","text":"<ul> <li>Best Practices - Best practices for development</li> <li>Tools - Tool types and patterns</li> <li>Testing Debugging - Testing and debugging guide</li> </ul>"},{"location":"Entry-Points/","title":"Entry Points","text":"<p>OpenSage has two main entry points for different use cases:</p> <ol> <li>OpenSage Web Entry - Interactive web UI for development and debugging</li> <li>Evaluation Entry - Batch evaluation on benchmarks</li> </ol> <p>Each entry point has a different workflow and use case. Click on the links above to see detailed step-by-step workflows.</p>"},{"location":"Entry-Points/#quick-comparison","title":"Quick Comparison","text":"Aspect opensage web Evaluations Use Case Development, debugging Performance measurement Interaction Interactive chat Batch processing Sessions Single long-lived Multiple short-lived Parallelism Single user Multiple tasks Output Real-time events Saved results files"},{"location":"Evaluation-Entry/","title":"Evaluations - Batch Processing Entry Point","text":"<p>Evaluation scripts run agents on benchmark datasets for performance measurement and testing.</p>"},{"location":"Evaluation-Entry/#command","title":"Command","text":"<pre><code>cd src/opensage/evaluations\npython cybergym/cybergym_vul_detection.py run \\\n  --agent-id my_agent \\\n  --config-path /path/to/config.toml \\\n  --max_llm_calls 75 \\\n  --use_multiprocessing \\\n  --max_workers 3\n</code></pre>"},{"location":"Evaluation-Entry/#step-by-step-workflow","title":"Step-by-Step Workflow","text":""},{"location":"Evaluation-Entry/#step-1-script-initialization","title":"Step 1: Script Initialization","text":"<ol> <li>Fire library parses command-line arguments</li> <li>Creates <code>Evaluation</code> class instance with parameters:</li> <li><code>agent_id</code>: Identifier for the agent</li> <li><code>config_path</code>: Path to TOML configuration</li> <li><code>max_llm_calls</code>: Maximum LLM calls per task</li> <li><code>use_multiprocessing</code>: Use processes vs threads</li> <li><code>max_workers</code>: Number of parallel workers</li> <li>Sets up logging and instrumentation (Langfuse, OpenTelemetry)</li> </ol>"},{"location":"Evaluation-Entry/#step-2-load-dataset","title":"Step 2: Load Dataset","text":"<pre><code>self.dataset = self._get_dataset()\n</code></pre> <ol> <li>Loads benchmark dataset (e.g., HuggingFace datasets, JSON files)</li> <li>Dataset contains multiple samples/tasks to evaluate</li> <li>Example: CyberGym dataset has vulnerability detection tasks</li> <li>Each sample contains:</li> <li>Task description</li> <li>Expected outputs (ground truth)</li> <li>Metadata (file paths, vulnerability info, etc.)</li> </ol>"},{"location":"Evaluation-Entry/#step-3-prepare-general-environment-_prepare_general_env","title":"Step 3: Prepare General Environment (<code>_prepare_general_env</code>)","text":"<p>This sets up shared resources used across all evaluation tasks.</p>"},{"location":"Evaluation-Entry/#31-create-base-configuration","title":"3.1 Create Base Configuration","text":"<ol> <li>Loads base configuration from TOML file</li> <li>Expands template variables</li> <li>Stores in class for later use</li> </ol>"},{"location":"Evaluation-Entry/#32-setup-evaluation-directories","title":"3.2 Setup Evaluation Directories","text":"<pre><code>self.eval_output_dir = Path(f\"evals/{self.agent_id}/...\")\nself.eval_output_dir.mkdir(parents=True, exist_ok=True)\n</code></pre> <ul> <li>Creates output directories for results</li> <li>Structure: <code>evals/{agent_id}/{benchmark_name}/{timestamp}/</code></li> <li>Stores agent outputs, logs, artifacts</li> </ul>"},{"location":"Evaluation-Entry/#step-4-generate-samples-parallel-execution","title":"Step 4: Generate Samples (Parallel Execution)","text":"<p>The evaluation runs tasks in parallel. Choose one mode:</p>"},{"location":"Evaluation-Entry/#mode-a-multiprocessing-generate","title":"Mode A: Multiprocessing (<code>generate()</code>)","text":"<pre><code>with ProcessPoolExecutor(max_workers=self.max_workers) as executor:\n    futures = {\n        executor.submit(_run_sample_in_process, self, sample): sample\n        for sample in self.dataset\n    }\n</code></pre> <ul> <li>Each sample runs in separate process</li> <li>True parallelism (bypasses Python GIL)</li> <li>Processes are isolated (no shared memory)</li> <li>Requires serializable data</li> </ul>"},{"location":"Evaluation-Entry/#mode-b-multithreading-generate_threaded","title":"Mode B: Multithreading (<code>generate_threaded()</code>)","text":"<pre><code>with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n    futures = {\n        executor.submit(run_sample_in_thread, sample): sample\n        for sample in self.dataset\n    }\n</code></pre> <ul> <li>Each sample runs in separate thread</li> <li>Shared memory (can share resources)</li> <li>Limited by GIL for CPU-bound tasks</li> <li>Better for I/O-bound operations</li> </ul>"},{"location":"Evaluation-Entry/#mode-c-single-thread-generate_single_thread","title":"Mode C: Single Thread (<code>generate_single_thread()</code>)","text":"<ul> <li>Sequential execution, one sample at a time</li> <li>Used for debugging</li> <li>Easier to debug issues</li> <li>Much slower</li> </ul>"},{"location":"Evaluation-Entry/#step-5-process-each-sample-_generate_sample-or-_run_sample_in_process","title":"Step 5: Process Each Sample (<code>_generate_sample</code> or <code>_run_sample_in_process</code>)","text":"<p>For each sample in the dataset:</p>"},{"location":"Evaluation-Entry/#51-create-evaluation-task","title":"5.1 Create Evaluation Task","text":"<pre><code>task = self._create_task(sample)\n</code></pre> <ol> <li>Extracts sample data</li> <li>Creates <code>EvaluationTask</code> object with:</li> <li><code>session_id</code>: Unique ID for this task</li> <li><code>sample</code>: Original sample data</li> <li><code>session</code>: Will be created next</li> <li>Metadata (task name, description, etc.)</li> </ol>"},{"location":"Evaluation-Entry/#52-create-opensage-session","title":"5.2 Create OpenSage Session","text":"<pre><code>import opensage\n\nsession = opensage.get_session(\n    session_id=task.session_id,\n    config_path=self.config_path,\n)\n</code></pre> <ul> <li>Creates isolated OpenSage session for this task</li> <li>Loads configuration</li> <li>Each task gets its own session (isolation)</li> </ul>"},{"location":"Evaluation-Entry/#53-prepare-task-specific-environment-_prepare_environment","title":"5.3 Prepare Task-Specific Environment (<code>_prepare_environment</code>)","text":"<p>This is benchmark-specific. Example for CyberGym:</p> <ol> <li>Extract code/data:</li> <li>Extracts source code to sandbox</li> <li>Copies test files, build scripts</li> <li> <p>Sets up project structure</p> </li> <li> <p>Initialize sandboxes:    <pre><code>session.sandboxes.initialize_shared_volumes()\nawait session.sandboxes.launch_all_sandboxes()\nawait session.sandboxes.initialize_all_sandboxes()\n</code></pre></p> </li> <li>Creates shared volumes</li> <li>Launches required sandbox containers</li> <li> <p>Initializes sandboxes (tools, dependencies)</p> </li> <li> <p>Set source directory:    <pre><code>session.config.src_dir_in_sandbox = \"/shared/code\"\n</code></pre></p> </li> <li> <p>Tells tools where to find source code</p> </li> <li> <p>Git repository setup (if applicable):</p> </li> <li>Finds git repository in sandbox</li> <li>Checks out main/master branch</li> <li>Updates <code>src_dir_in_sandbox</code> to repo path</li> </ol>"},{"location":"Evaluation-Entry/#54-load-agent","title":"5.4 Load Agent","text":"<pre><code>mk_agent = self._load_mk_agent()\nagent = mk_agent(session_id=task.session_id)\n</code></pre> <ol> <li>Imports agent module</li> <li>Calls <code>mk_agent()</code> function with session ID</li> <li>Agent is configured for this specific session</li> <li>Agent has access to task-specific sandboxes and resources</li> </ol>"},{"location":"Evaluation-Entry/#55-create-adk-session-and-runner","title":"5.5 Create ADK Session and Runner","text":"<pre><code>inner_session_service = InMemorySessionService()\nawait inner_session_service.create_session(\n    app_name=app_name,\n    user_id=self.user_id + \"_\" + meta_data,\n    session_id=task.session_id,\n    state={\"opensage_session_id\": task.session_id},\n)\n\nrunner = Runner(\n    agent=agent,\n    app_name=app_name,\n    session_service=inner_session_service,\n)\n</code></pre> <ul> <li>Creates ADK session that maps to OpenSage session</li> <li>Stores <code>opensage_session_id</code> in session state</li> <li>Creates ADK Runner for agent execution</li> </ul>"},{"location":"Evaluation-Entry/#56-run-agent","title":"5.6 Run Agent","text":"<pre><code>run_config = RunConfig(max_llm_calls=self.max_llm_calls)\n\nasync for event in runner.run_async(\n    user_id=user_id,\n    session_id=task.session_id,\n    run_config=run_config,\n    new_message=types.Content(parts=[types.Part(text=task.prompt)]),\n):\n    # Process events\n    if isinstance(event, types.FunctionResponse):\n        # Tool execution results\n    elif isinstance(event, types.Candidate):\n        # Agent responses\n</code></pre> <ol> <li>Runner starts agent execution:</li> <li>Sends prompt to agent</li> <li> <p>Agent enters reason-act loop</p> </li> <li> <p>Agent reasoning:</p> </li> <li>Calls LLM for reasoning</li> <li>Decides which tools to use</li> <li> <p>Generates function calls</p> </li> <li> <p>Tool execution:</p> </li> <li>Runner executes tools in sandbox</li> <li>Tools access session resources</li> <li> <p>Results returned to agent</p> </li> <li> <p>Iteration:</p> </li> <li>Agent processes tool results</li> <li>Decides next action</li> <li> <p>Continues until completion or max calls</p> </li> <li> <p>Completion:</p> </li> <li>Agent generates final response</li> <li>Runner finishes execution</li> <li>Events collected</li> </ol>"},{"location":"Evaluation-Entry/#57-collect-results","title":"5.7 Collect Results","text":"<pre><code>result = {\n    \"session_id\": task.session_id,\n    \"prompt\": task.prompt,\n    \"response\": agent_response,\n    \"events\": events,\n    \"metadata\": {...},\n}\n</code></pre> <ul> <li>Extracts agent response</li> <li>Collects execution metadata:</li> <li>Number of LLM calls</li> <li>Tools used</li> <li>Execution time</li> <li>Errors (if any)</li> </ul>"},{"location":"Evaluation-Entry/#58-save-results","title":"5.8 Save Results","text":"<pre><code>self._save_result(task, result)\n</code></pre> <ul> <li>Saves result to file (JSON)</li> <li>Location: <code>evals/{agent_id}/{benchmark}/results/{task_id}.json</code></li> <li>Includes full event history for analysis</li> </ul>"},{"location":"Evaluation-Entry/#59-cleanup-task-session","title":"5.9 Cleanup Task Session","text":"<pre><code>opensage.cleanup_session(task.session_id)\n</code></pre> <ul> <li>Stops sandbox containers</li> <li>Removes shared volumes</li> <li>Cleans up session resources</li> <li>Frees Docker resources</li> </ul>"},{"location":"Evaluation-Entry/#step-6-collect-all-results","title":"Step 6: Collect All Results","text":"<p>After all samples complete:</p> <ol> <li>Aggregates results from all tasks</li> <li>Collects statistics:</li> <li>Success rate</li> <li>Average execution time</li> <li>Tool usage patterns</li> <li>Error rates</li> </ol>"},{"location":"Evaluation-Entry/#step-7-evaluate-results-evaluate","title":"Step 7: Evaluate Results (<code>evaluate()</code>)","text":"<pre><code>self.evaluate()\n</code></pre> <ol> <li>Load ground truth:</li> <li>Loads expected outputs from dataset</li> <li> <p>Loads agent results from files</p> </li> <li> <p>Compare outputs:</p> </li> <li>Compares agent output vs ground truth</li> <li> <p>Calculates metrics:</p> <ul> <li>Accuracy</li> <li>Precision/Recall (if applicable)</li> <li>Custom benchmark metrics</li> </ul> </li> <li> <p>Generate report:</p> </li> <li>Creates evaluation report</li> <li>Includes metrics, statistics, examples</li> <li> <p>Saves to <code>evals/{agent_id}/{benchmark}/evaluation_report.json</code></p> </li> <li> <p>Display summary:</p> </li> <li>Prints metrics to console</li> <li>Shows top failures/successes</li> <li>Provides analysis</li> </ol>"},{"location":"Evaluation-Entry/#key-characteristics","title":"Key Characteristics","text":""},{"location":"Evaluation-Entry/#isolation","title":"Isolation","text":"<ul> <li>Each task gets its own OpenSage session</li> <li>Separate sandbox containers</li> <li>No interference between tasks</li> </ul>"},{"location":"Evaluation-Entry/#parallelism","title":"Parallelism","text":"<ul> <li>Multiple tasks run simultaneously</li> <li>Configurable worker count</li> <li>Process or thread-based execution</li> </ul>"},{"location":"Evaluation-Entry/#reproducibility","title":"Reproducibility","text":"<ul> <li>Deterministic task execution</li> <li>Results saved with full event history</li> <li>Can replay specific tasks</li> </ul>"},{"location":"Evaluation-Entry/#resource-management","title":"Resource Management","text":"<ul> <li>Sessions cleaned up after each task</li> <li>Containers stopped and removed</li> <li>Prevents resource leaks</li> </ul>"},{"location":"Evaluation-Entry/#comparison-with-opensage-web","title":"Comparison with opensage web","text":"Aspect opensage web Evaluations Purpose Development, debugging Performance measurement Sessions Single long-lived session Multiple short-lived sessions Interaction Interactive chat Batch processing Parallelism Single user Multiple tasks in parallel Cleanup Manual (on exit) Automatic (per task) Output Real-time events Saved results files"},{"location":"Evaluation-Entry/#example-evaluation-flow","title":"Example Evaluation Flow","text":"<pre><code>Dataset (100 tasks)\n  \u2193\nProcess Pool (3 workers)\n  \u251c\u2500 Worker 1: Task 1 \u2192 Session 1 \u2192 Agent \u2192 Result 1\n  \u251c\u2500 Worker 2: Task 2 \u2192 Session 2 \u2192 Agent \u2192 Result 2\n  \u2514\u2500 Worker 3: Task 3 \u2192 Session 3 \u2192 Agent \u2192 Result 3\n  \u251c\u2500 Worker 1: Task 4 \u2192 Session 4 \u2192 Agent \u2192 Result 4\n  ...\n  \u2193\nAll Results Collected\n  \u2193\nEvaluation (compare vs ground truth)\n  \u2193\nReport Generated\n</code></pre>"},{"location":"Evaluation-Entry/#related-topics","title":"Related Topics","text":"<ul> <li>Entry Points - Overview of entry points</li> <li>Testing Debugging - Debugging evaluations</li> </ul>"},{"location":"Getting-Started/","title":"Getting Started","text":""},{"location":"Getting-Started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11+ (recommended)</li> <li><code>uv</code> package manager (required)</li> <li>Docker (for sandbox execution)</li> <li>CodeQL (optional, for CodeQL analysis)</li> </ul>"},{"location":"Getting-Started/#installation","title":"Installation","text":""},{"location":"Getting-Started/#step-1-install-uv","title":"Step 1: Install uv","text":"<pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre>"},{"location":"Getting-Started/#step-2-clone-and-setup","title":"Step 2: Clone and Setup","text":"<pre><code># Clone the repository\ngit clone https://github.com/OpenSage-ADK/OpenSage.git\ncd OpenSage\n\n# Create virtual environment\nuv venv --python \"python3.11\" \".venv\"\nsource .venv/bin/activate\n\n# Install dependencies\nuv sync\n\n# Install pre-commit hooks\nuv run pre-commit install\n</code></pre>"},{"location":"Getting-Started/#step-3-additional-setup","title":"Step 3: Additional Setup","text":"<p>CodeQL Setup (Optional): <pre><code>cd \"src/opensage/sandbox_scripts\"\n\n# Download CodeQL bundle (current default expected by the framework)\nwget \"https://github.com/github/codeql-action/releases/download/codeql-bundle-v2.18.4/codeql-bundle-linux64.tar.gz\"\n\n# Extract only the `codeql/` directory so `src/opensage/sandbox_scripts/codeql/codeql` exists\ntar -xzf \"codeql-bundle-linux64.tar.gz\" \"codeql\"\nrm -f \"codeql-bundle-linux64.tar.gz\"\n</code></pre></p>"},{"location":"Getting-Started/#step-4-verify-installation","title":"Step 4: Verify Installation","text":"<pre><code># Check OpenSage CLI is available\nuv run opensage --help\n\n# Check optional external dependencies (Docker / CodeQL / kubectl, etc.)\nuv run opensage dependency-check\n</code></pre>"},{"location":"Getting-Started/#tools","title":"Tools","text":"<p>OpenSage agents can use Python tools, filesystem-discovered Skills, and MCP toolsets.</p> <ul> <li>Adding a New Tool: How to add new tools/skills/toolsets.</li> </ul>"},{"location":"Getting-Started/#creating-your-own-agent","title":"Creating Your Own Agent","text":"<p>This section shows the minimal structure and conventions for writing an agent that OpenSage can load via <code>opensage web</code> and evaluation entry points.</p>"},{"location":"Getting-Started/#1-agent-directory-layout","title":"1) Agent directory layout","text":"<p>Create a directory for your agent:</p> <pre><code>my_agent/\n\u2514\u2500\u2500 agent.py\n</code></pre> <p>OpenSage loads your agent by importing <code>agent.py</code> and calling the <code>mk_agent</code> factory function.</p>"},{"location":"Getting-Started/#2-agentpy-implement-mk_agentsession_id","title":"2) <code>agent.py</code>: implement <code>mk_agent(session_id, ...)</code>","text":"<p><code>mk_agent</code> is a factory that receives a session id and returns the root ADK agent instance (your \u201cmain\u201d agent). It should be deterministic and avoid doing heavy work at import time.</p> <p>What is <code>session_id</code>?</p> <p><code>session_id</code> is a user-chosen string that identifies one OpenSage run/session. It is used to scope and isolate session resources (sandboxes, config, Neo4j clients, dynamic agents, etc.). You can set it to any value you like, but it should be unique per concurrent run (using a UUID is a common choice).</p> <p>Minimal template:</p> <pre><code>import os\nfrom typing import Optional\n\nfrom google.adk.models import BaseLlm\nfrom google.adk.models.lite_llm import LiteLlm\n\nimport opensage\nfrom opensage.agents import OpenSageAgent\n\n\ndef mk_agent(\n    session_id: str,\n    model: Optional[BaseLlm] = None,\n):\n    # Link to the session created by OpenSage (sandboxes/config/neo4j live here).\n    session = opensage.get_session(session_id)\n\n    if model is None:\n        model = LiteLlm(\n            model=\"YOUR_MODEL_NAME\",\n            api_key=os.environ.get(\"YOUR_API_KEY\"),\n        )\n\n    root_agent = OpenSageAgent(\n        name=\"my_agent\",\n        description=\"My custom OpenSage agent.\",\n        model=model,\n        instruction=\"You are a helpful assistant.\",\n        # Flags / features:\n        enabled_skills=\"all\",\n        enable_memory_management=False,\n        # ADK tools you want the agent to call:\n        tools=[],\n        # Optional: static sub-agents (if you have them)\n        sub_agents=[],\n    )\n    return root_agent\n</code></pre>"},{"location":"Getting-Started/#3-base-agent-attributes-flags-what-you-typically-customize","title":"3) Base agent attributes / flags (what you typically customize)","text":"<p>The OpenSage base agent extends ADK\u2019s <code>LlmAgent</code> and adds OpenSage-specific capabilities. The most commonly used fields are:</p> <ul> <li><code>name</code> / <code>description</code>: identify the agent in logs and the UI.</li> <li><code>model</code>: the LLM backend for reasoning.</li> <li><code>instruction</code>: system instruction/policy for the agent.</li> <li><code>tools</code>: Python tools and toolsets (including dynamic sub-agent tools).</li> <li><code>sub_agents</code>: static sub-agents you attach at construction time.</li> <li><code>enabled_skills</code>: which filesystem Skills under <code>bash_tools/</code> are exposed.</li> <li><code>None</code>: enable no Skills</li> <li><code>\"all\"</code> / <code>[\"all\"]</code>: enable only top-level Skills</li> <li><code>List[str]</code>: prefix allowlist (e.g. <code>\"retrieval\"</code> or <code>\"static_analysis/search-function\"</code>)</li> <li><code>enable_memory_management</code>: enables a dedicated memory management sub-agent   (often exposed as a <code>memory_management_agent</code> tool) that mediates interactions   with short-term (session history/trace) and long-term (Neo4j graph memory).</li> <li><code>tool_combos</code> (optional): group multi-step tool workflows into a single callable tool.</li> </ul>"},{"location":"Getting-Started/#4-configuration","title":"4) Configuration","text":"<p>OpenSage sessions are configured via TOML. You can start from the default config and override only what you need (sandboxes, build commands, plugins, etc.).</p> <p>When running the web UI, pass your config path:</p> <pre><code>uv run opensage web --config \"/path/to/config.toml\" --agent \"/path/to/my_agent\"\n</code></pre> <p>Minimal workable config (example <code>opensage.toml</code>) that can start the web UI and launch the default <code>main</code> sandbox:</p> <pre><code># Optional: a human-readable label used for naming/logging. It can be any string.\ntask_name = \"my_task\"\n\n[sandbox]\nbackend = \"native\"\n\n[sandbox.sandboxes.main]\nimage = \"ubuntu:20.04_main\"\nproject_relative_dockerfile_path = \"src/opensage/templates/dockerfiles/main/Dockerfile\"\n\n[sandbox.sandboxes.main.build_args]\nBASE_IMAGE = \"ubuntu:20.04\"\n</code></pre> <p>See the full field reference in Configuration.</p>"},{"location":"Getting-Started/#5-turning-on-common-features","title":"5) Turning on common features","text":"<p>Enable memory agent</p> <ul> <li>In <code>agent.py</code>: set <code>enable_memory_management=True</code>.</li> </ul> <p>Enable dynamic sub-agents</p> <p>Dynamic sub-agents are enabled by adding the dynamic-subagent tools to your agent\u2019s <code>tools</code> list (e.g. <code>create_subagent</code>, <code>list_active_agents</code>, <code>call_subagent_as_tool</code>). OpenSage will manage their lifecycle under the current session.</p> <p>If you want dynamic agents to persist across runs, set an <code>agent_storage_path</code> in your TOML configuration (see Configuration).</p>"},{"location":"Getting-Started/#6-examples-used-by-integration-tests","title":"6) Examples (used by integration tests)","text":"<p>The repo includes small \u201cfeature agents\u201d used in integration tests. Use them as starting points:</p> <ul> <li><code>examples/agents_with_features/sample_dynamic_subagent/</code></li> <li><code>examples/agents_with_features/sample_agent_ensemble/</code></li> <li><code>examples/agents_with_features/sample_summarization/</code></li> <li><code>examples/agents_with_features/sample_neo4j_logging/</code></li> <li><code>examples/agents_with_features/sample_tool_combo/</code></li> </ul> <p>Run one in the web UI by pointing <code>--agent</code> to the example directory and <code>--config</code> to the config file shipped alongside it.</p>"},{"location":"Getting-Started/#adding-tools-to-your-agent","title":"Adding tools to your agent","text":"<p>OpenSage supports three tool types you can enable in your agent:</p> <ol> <li>Python tools (callable functions)</li> <li>Agent Skills (bash/Python scripts discovered from <code>bash_tools/</code>)</li> <li>MCP toolsets (external services exposed via MCP)</li> </ol>"},{"location":"Getting-Started/#1-python-tools","title":"1) Python tools","text":"<p>Any callable can be a tool. The function signature becomes the tool schema, and the docstring is shown to the model as the tool description.</p> <pre><code>def greet(name: str) -&gt; str:\n    \"\"\"Return a friendly greeting.\"\"\"\n    return f\"Hello, {name}!\"\n</code></pre> <p>Enable it by adding it to <code>tools</code>:</p> <pre><code>root_agent = OpenSageAgent(\n    name=\"my_agent\",\n    model=...,\n    instruction=\"...\",\n    tools=[greet],\n)\n</code></pre>"},{"location":"Getting-Started/#2-agent-skills-bash-script-tools","title":"2) Agent Skills (bash script tools)","text":"<p>Skills are filesystem-discovered tools that run inside sandboxes.</p> <p>Directory layout:</p> <pre><code>src/opensage/bash_tools/\n\u2514\u2500\u2500 category/\n    \u2514\u2500\u2500 tool-name/\n        \u251c\u2500\u2500 SKILL.md\n        \u2514\u2500\u2500 scripts/\n            \u2514\u2500\u2500 tool_script.sh\n</code></pre> <p><code>SKILL.md</code> outline:</p> <pre><code>---\nname: my-tool\ndescription: Tool description\nshould_run_in_sandbox: main\n---\n\n## Usage\n\n    scripts/tool_script.sh &lt;input&gt; --option value\n\n## Requires Sandbox\n\nmain\n</code></pre> <p>Enable Skills using <code>enabled_skills</code> on the base agent:</p> <ul> <li><code>None</code>: enable no Skills</li> <li><code>\"all\"</code> / <code>[\"all\"]</code>: enable only top-level Skills (<code>&lt;root&gt;/*/SKILL.md</code>)</li> <li><code>List[str]</code>: prefix allowlist (e.g. <code>\"retrieval\"</code> or <code>\"static_analysis/search-function\"</code>)</li> </ul> <p>Example:</p> <pre><code>root_agent = OpenSageAgent(\n    name=\"my_agent\",\n    model=...,\n    instruction=\"...\",\n    enabled_skills=[\"retrieval\", \"static_analysis/search-function\"],\n)\n</code></pre>"},{"location":"Getting-Started/#3-mcp-toolsets","title":"3) MCP toolsets","text":"<p>To use an MCP toolset, write a getter function that returns an <code>MCPToolset</code> instance. The endpoint URL should come from config and be resolved per-session via <code>get_mcp_url_from_session_id(\"&lt;service&gt;\", session_id)</code>.</p> <pre><code>from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset, SseConnectionParams\n\nfrom opensage.toolbox.decorators import requires_sandbox, safe_tool_execution\nfrom opensage.utils.agent_utils import get_mcp_url_from_session_id\n\n\n@safe_tool_execution\n@requires_sandbox(\"gdb_mcp\")\ndef get_gdb_toolset(session_id: str) -&gt; MCPToolset:\n    \"\"\"Return a GDB MCP toolset for the current session.\"\"\"\n    url = get_mcp_url_from_session_id(\"gdb_mcp\", session_id)\n    return MCPToolset(connection_params=SseConnectionParams(url=url))\n</code></pre> <p>Enable it by adding the getter to <code>tools</code>:</p> <pre><code>root_agent = OpenSageAgent(\n    name=\"my_agent\",\n    model=...,\n    instruction=\"...\",\n    tools=[get_gdb_toolset],\n)\n</code></pre> <p>MCP service endpoints are configured in TOML (host/port). See Configuration for the MCP section.</p>"},{"location":"Getting-Started/#next-steps","title":"Next Steps","text":"<ul> <li>Project Structure - Understand the codebase structure</li> <li>Development Guides - Start developing</li> </ul>"},{"location":"Introduction/","title":"Introduction","text":""},{"location":"Introduction/#what-is-opensage","title":"What is OpenSage?","text":"<p>OpenSage (Open Self-programming Agent Generation Engine) is an AI agent framework built on top of Google ADK (Agent Development Kit). It represents a paradigm shift from \"Agent Development 1.0\" to \"Agent Development 2.0\" \u2014 transitioning from agents that execute predefined structures to agents that can dynamically build and manage their own systems at runtime.</p>"},{"location":"Introduction/#core-value-proposition","title":"Core Value Proposition","text":""},{"location":"Introduction/#from-agent-using-system-to-agent-building-system","title":"From \"Agent Using System\" to \"Agent Building System\"","text":"<p>Agent Development 1.0 (Traditional Frameworks):</p> <ul> <li>System structure pre-defined by humans (agent topology, workflows, tool sets)</li> <li>Agents can only choose actions within given structures</li> <li>Extending to new tasks requires significant manual refactoring</li> <li>Essentially human-centered agent building</li> </ul> <p>Agent Development 2.0 (OpenSage):</p> <ul> <li>Agents upgrade from \"executing predefined structures\" to \"autonomously   building and managing structures\"</li> <li>Humans provide minimal, stable system-level scaffolding</li> <li>Everything else is generated, composed, and scheduled by AI at runtime</li> <li>Agents can \"invent new capabilities\" rather than just calling existing ones</li> </ul>"},{"location":"Introduction/#key-features","title":"Key Features","text":"<ul> <li>AI-written tools as first-class system entities</li> <li>Runtime sub-agent creation and dynamic agent topology</li> <li>Memory as manageable resource (graph-structured, Neo4j-backed)</li> <li>Session-based resource management with complete isolation</li> <li>Multi-sandbox support (Docker, Kubernetes under development)</li> <li>Dynamic tool loading and runtime tool generation</li> <li>Agent ensemble for parallel exploration</li> <li>Integration with security tools (Joern, CodeQL, GDB, Neo4j)</li> <li>Evaluation framework for security benchmarks</li> </ul>"},{"location":"Introduction/#why-opensage","title":"Why OpenSage?","text":"<p>OpenSage was designed to make self-programming agent development feel more like software development. It provides:</p> <ol> <li>Isolation: Each agent session has its own resources, preventing interference</li> <li>Flexibility: Easy to add new tools, sandboxes, and agents</li> <li>Evolution: Tools and agents can be created and modified at runtime</li> <li>Integration: Seamless integration with existing security analysis tools</li> <li>Composability: Build complex agents from simple components</li> <li>Scalability: Kubernetes support (under development)</li> </ol>"},{"location":"Introduction/#next-steps","title":"Next Steps","text":"<ul> <li>Getting Started - Set up your development environment</li> <li>Core Components - Understand the core building blocks</li> <li>Entry Points - Understand how to use OpenSage</li> </ul>"},{"location":"OpenSage-Web-Entry/","title":"opensage web - Interactive Development Entry Point","text":"<p>The <code>opensage web</code> command starts an interactive web UI for developing and debugging agents.</p>"},{"location":"OpenSage-Web-Entry/#cli-commands","title":"CLI Commands","text":""},{"location":"OpenSage-Web-Entry/#opensage-web","title":"opensage web","text":"<p>Starts an interactive web UI for agent development and debugging.</p> <pre><code>uv run opensage web \\\n  --config /path/to/config.toml \\\n  --agent /path/to/agent_dir \\\n  --port 8000 \\\n  --neo4j_logging  # optional\n</code></pre>"},{"location":"OpenSage-Web-Entry/#opensage-dependency-check","title":"opensage dependency-check","text":"<p>Checks if external dependencies are properly installed.</p> <pre><code>uv run opensage dependency-check\n</code></pre> <p>This command verifies: - CodeQL: Required for CodeQL static analysis features - Docker: Required for native Docker sandbox backend - kubectl: Required for Kubernetes sandbox backend</p> <p>All dependencies are optional unless you plan to use the corresponding features. The command will show: - Green checkmarks for available dependencies - Yellow warnings for missing optional dependencies - Red errors for missing required dependencies (if any)</p> <p>Example Output:</p> <pre><code>Checking OpenSage dependencies...\n\nChecking CodeQL...\n  [OK] CodeQL binary found at /path/to/codeql\n\nChecking Docker...\n  [OK] Docker daemon is running and accessible\n\nChecking kubectl...\n  [WARN] kubectl command not found in PATH. Install kubectl to use Kubernetes backend.\n    Note: Only required when using Kubernetes sandbox backend\n\n============================================================\n[WARN] Some dependencies missing (2/3 available)\n\nNote: Missing dependencies are optional unless you plan to use\nthe corresponding features.\n============================================================\n</code></pre>"},{"location":"OpenSage-Web-Entry/#step-by-step-workflow","title":"Step-by-Step Workflow","text":""},{"location":"OpenSage-Web-Entry/#step-1-command-parsing-and-validation","title":"Step 1: Command Parsing and Validation","text":"<ol> <li>CLI parses command-line arguments</li> <li>Validates that <code>config_path</code> exists and is a file</li> <li>Validates that <code>agent_dir</code> exists and is a directory</li> <li>Sets up logging based on <code>--log_level</code> option</li> </ol>"},{"location":"OpenSage-Web-Entry/#step-2-optional-neo4j-logging-setup","title":"Step 2: Optional Neo4j Logging Setup","text":"<p>If <code>--neo4j_logging</code> flag is provided: 1. Imports <code>enable_neo4j_logging</code> from <code>opensage.features.agent_history_tracker</code> 2. Enables Neo4j logging via monkey patches 3. This allows event logging to Neo4j for analysis</p>"},{"location":"OpenSage-Web-Entry/#step-3-environment-preparation-_prepare_environment_async","title":"Step 3: Environment Preparation (<code>_prepare_environment_async</code>)","text":"<p>This is the core setup phase that creates the OpenSage session and initializes all resources.</p>"},{"location":"OpenSage-Web-Entry/#31-create-session-id","title":"3.1 Create Session ID","text":"<ul> <li>Generates a unique UUID for the session</li> <li>Format: <code>str(uuid.uuid4())</code></li> <li>Example: <code>\"550e8400-e29b-41d4-a716-446655440000\"</code></li> </ul>"},{"location":"OpenSage-Web-Entry/#32-create-session","title":"3.2 Create Session","text":"<p><pre><code>import opensage\n\nsession = opensage.get_session(\n    session_id=session_id,\n    config_path=config_path\n)\n</code></pre> - Loads TOML configuration file - Expands template variables (e.g., <code>${VAR_NAME}</code>) - Creates a session instance with all managers:   - <code>config</code>: Configuration manager   - <code>agents</code>: DynamicAgentManager   - <code>sandboxes</code>: SandboxManager   - <code>neo4j</code>: Neo4j client manager   - <code>ensemble</code>: Ensemble manager</p>"},{"location":"OpenSage-Web-Entry/#33-load-agent-and-collect-dependencies","title":"3.3 Load Agent and Collect Dependencies","text":"<p><pre><code>mk_agent = _load_mk_agent_from_dir(agent_dir)\ndummy_agent = mk_agent(session_id=session_id)\nsandbox_dependencies = collect_sandbox_dependencies(dummy_agent)\n</code></pre> - Dynamically imports <code>agent.py</code> from the agent directory - Extracts the <code>mk_agent</code> function - Creates a dummy agent instance to analyze dependencies - Collects which sandbox types the agent requires (e.g., <code>{\"main\", \"joern\", \"neo4j\"}</code>)</p>"},{"location":"OpenSage-Web-Entry/#34-prune-unused-sandboxes","title":"3.4 Prune Unused Sandboxes","text":"<ul> <li>Compares required sandboxes with configured sandboxes</li> <li>Removes sandbox configurations that are not needed</li> <li>Example: If agent only needs <code>{\"main\", \"joern\"}</code>, removes <code>gdb_mcp</code>, <code>pdb_mcp</code>, etc.</li> <li>This optimizes startup time by not launching unnecessary containers</li> </ul>"},{"location":"OpenSage-Web-Entry/#35-initialize-shared-volumes","title":"3.5 Initialize Shared Volumes","text":"<p><pre><code>session.sandboxes.initialize_shared_volumes()\n</code></pre> - Creates Docker volumes for shared data:   - <code>scripts_volume</code>: Read-only scripts and tools   - <code>data_volume</code>: Read-write data directory - Configures volume mounts for all sandbox containers - Volumes are shared across all sandboxes in the session</p>"},{"location":"OpenSage-Web-Entry/#36-launch-sandbox-containers","title":"3.6 Launch Sandbox Containers","text":"<p><pre><code>await session.sandboxes.launch_all_sandboxes()\n</code></pre> For each required sandbox type: 1. Gets sandbox configuration from <code>session.config.sandbox.sandboxes[sandbox_type]</code> 2. Creates Docker container (or connects to existing one) 3. Sets up network, volumes, environment variables 4. Starts the container 5. Stores sandbox instance in <code>session.sandboxes._sandboxes[sandbox_type]</code></p>"},{"location":"OpenSage-Web-Entry/#37-initialize-sandboxes","title":"3.7 Initialize Sandboxes","text":"<p><pre><code>await session.sandboxes.initialize_all_sandboxes(continue_on_error=True)\n</code></pre> For each sandbox: 1. Finds the appropriate initializer (e.g., <code>JoernInitializer</code>, <code>FuzzInitializer</code>) 2. Calls <code>async_initialize()</code> method:    - Installs tools and dependencies    - Sets up environment    - Prepares resources    - Example: Joern initializer runs CPG generation scripts 3. Marks sandbox as ready 4. Continues even if one sandbox fails (due to <code>continue_on_error=True</code>)</p>"},{"location":"OpenSage-Web-Entry/#step-4-load-agent","title":"Step 4: Load Agent","text":"<pre><code>mk_agent = _load_mk_agent_from_dir(agent_dir)\nroot_agent = mk_agent(session_id=session_id)\n</code></pre> <ol> <li>Imports agent module again (ensuring latest code)</li> <li>Calls <code>mk_agent()</code> with the session ID</li> <li>Agent constructor:</li> <li>Gets session via <code>opensage.get_session(session_id)</code></li> <li>Loads dynamic tools from filesystem (if enabled)</li> <li>Sets up tool combos, sub-agents, etc.</li> <li>Returns configured agent instance</li> </ol>"},{"location":"OpenSage-Web-Entry/#step-5-load-plugins","title":"Step 5: Load Plugins","text":"<pre><code>enabled_plugins = session.config.plugins.enabled or []\nplugins = load_plugins(enabled_plugins)\n</code></pre> <ol> <li>Reads plugin list from configuration</li> <li>Loads plugin classes dynamically</li> <li>Instantiates plugin objects</li> <li>Returns list of plugin instances</li> </ol>"},{"location":"OpenSage-Web-Entry/#step-6-create-adk-services","title":"Step 6: Create ADK Services","text":"<pre><code>session_service = InMemorySessionServiceBridge()\nartifact_service = InMemoryArtifactService()\nmemory_service = InMemoryMemoryService()\ncredential_service = InMemoryCredentialService()\neval_sets_manager = LocalEvalSetsManager(agents_dir=agents_dir_parent)\neval_set_results_manager = LocalEvalSetResultsManager(agents_dir=agents_dir_parent)\n</code></pre> <ul> <li>Creates in-memory services for ADK integration</li> <li>Session service bridges ADK sessions with OpenSage sessions</li> <li>Other services are standard ADK in-memory implementations</li> </ul>"},{"location":"OpenSage-Web-Entry/#step-7-determine-app-name","title":"Step 7: Determine App Name","text":"<pre><code>app_name = os.path.basename(os.path.dirname(agent_dir.rstrip(os.sep)))\n</code></pre> <ul> <li>Extracts parent directory name as app name</li> <li>Example: <code>/path/to/examples/agents/my_agent</code> \u2192 <code>app_name = \"agents\"</code></li> </ul>"},{"location":"OpenSage-Web-Entry/#step-8-create-web-server","title":"Step 8: Create Web Server","text":"<pre><code>web_server = WebServer(\n    app_name=app_name,\n    root_agent=root_agent,\n    fixed_session_id=session_id,\n    session_service=session_service,\n    artifact_service=artifact_service,\n    memory_service=memory_service,\n    credential_service=credential_service,\n    eval_sets_manager=eval_sets_manager,\n    eval_set_results_manager=eval_set_results_manager,\n    plugins=plugins,\n)\n</code></pre> <ul> <li>Creates the web server instance</li> <li>Configures all services and agent</li> <li>Sets up FastAPI endpoints for:</li> <li>Agent execution (<code>/run</code>)</li> <li>Server-Sent Events (<code>/events</code>)</li> <li>Live streaming (<code>/live</code>)</li> <li>Session management</li> <li>Artifact access</li> <li>Dev UI static files</li> </ul>"},{"location":"OpenSage-Web-Entry/#step-9-pre-create-adk-session","title":"Step 9: Pre-create ADK Session","text":"<pre><code>await session_service.create_session(\n    app_name=web_server.app_name,\n    user_id=\"user\",\n    state={\"opensage_session_id\": session_id},\n    session_id=session_id,\n)\n</code></pre> <ul> <li>Creates ADK session that maps to OpenSage session</li> <li>Stores <code>opensage_session_id</code> in session state</li> <li>This allows ADK Runner to find the OpenSage session</li> </ul>"},{"location":"OpenSage-Web-Entry/#step-10-create-fastapi-app","title":"Step 10: Create FastAPI App","text":"<pre><code>app = web_server.get_fast_api_app(allow_origins=None, enable_dev_ui=True)\n</code></pre> <ul> <li>Generates FastAPI application with all routes</li> <li>Enables CORS middleware</li> <li>Mounts static files for Dev UI</li> <li>Sets up WebSocket endpoints</li> </ul>"},{"location":"OpenSage-Web-Entry/#step-11-start-uvicorn-server","title":"Step 11: Start Uvicorn Server","text":"<pre><code>config = uvicorn.Config(app, host=host, port=port, reload=reload, log_level=log_level.lower())\nserver = uvicorn.Server(config)\nserver.run()\n</code></pre> <ul> <li>Configures Uvicorn ASGI server</li> <li>Starts server on specified host/port</li> <li>If <code>reload=True</code>, watches for code changes and restarts</li> <li>Server runs until interrupted (Ctrl+C)</li> </ul>"},{"location":"OpenSage-Web-Entry/#user-interaction-flow","title":"User Interaction Flow","text":"<p>Once the server is running:</p> <ol> <li>User opens browser to <code>http://localhost:8000</code></li> <li>Dev UI loads and connects to backend</li> <li>User types a message in the chat interface</li> <li>Frontend sends POST request to <code>/run</code> endpoint</li> <li>Web server creates ADK Runner with the agent</li> <li>Runner executes agent with user message</li> <li>Events are streamed back via Server-Sent Events</li> <li>Frontend displays agent responses in real-time</li> <li>User can continue conversation or start new session</li> </ol>"},{"location":"OpenSage-Web-Entry/#key-differences-from-evaluation","title":"Key Differences from Evaluation","text":"<ul> <li>Single session: One OpenSage session for the entire web server</li> <li>Interactive: User can send multiple messages</li> <li>Real-time: Events streamed as they happen</li> <li>Development-focused: Hot reload, debugging tools, Dev UI</li> <li>Long-lived: Server runs until manually stopped</li> </ul>"},{"location":"OpenSage-Web-Entry/#cleanup","title":"Cleanup","text":"<p>When server stops (Ctrl+C): 1. Signal handler calls <code>cleanup_all_sessions()</code> 2. All sandbox containers are stopped 3. Shared volumes are cleaned up (if configured) 4. Session registry is cleared</p>"},{"location":"OpenSage-Web-Entry/#related-topics","title":"Related Topics","text":"<ul> <li>Development Guides - How to develop agents</li> <li>Testing Debugging - Debugging with web UI</li> </ul>"},{"location":"Project-Structure/","title":"Project Structure","text":""},{"location":"Project-Structure/#directory-overview","title":"Directory Overview","text":"<pre><code>OpenSage/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 docs/                    # Docs source (MkDocs)\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 opensage/              # Core Python package (current layout)\n\u2502       \u251c\u2500\u2500 agents/          # Base agent + tool loading\n\u2502       \u251c\u2500\u2500 bash_tools/      # Agent Skills (SKILL.md + scripts/)\n\u2502       \u251c\u2500\u2500 cli/             # CLI entry points (opensage web / dependency-check)\n\u2502       \u251c\u2500\u2500 config/          # TOML config system + dataclasses\n\u2502       \u251c\u2500\u2500 evaluations/     # Benchmarks + evaluation runners\n\u2502       \u251c\u2500\u2500 features/        # Feature flags / optional behaviors\n\u2502       \u251c\u2500\u2500 memory/          # Neo4j-backed memory (search/update/tools)\n\u2502       \u251c\u2500\u2500 plugins/         # ADK plugins\n\u2502       \u251c\u2500\u2500 sandbox/         # Sandbox backends + initializers\n\u2502       \u251c\u2500\u2500 sandbox_scripts/ # Scripts invoked inside sandboxes\n\u2502       \u251c\u2500\u2500 session/         # Session + managers (sandboxes/agents/neo4j/ensemble)\n\u2502       \u251c\u2500\u2500 templates/       # Default configs + Dockerfiles\n\u2502       \u251c\u2500\u2500 toolbox/         # Python tool wrappers / MCP toolsets\n\u2502       \u251c\u2500\u2500 util_agents/     # Utility sub-agents (e.g. memory management)\n\u2502       \u2514\u2500\u2500 utils/           # Shared utilities\n\u251c\u2500\u2500 examples/                # Example agents and configs\n\u251c\u2500\u2500 tests/                   # Unit/integration tests\n\u2514\u2500\u2500 third_party/             # External benchmark/tool dependencies\n</code></pre>"},{"location":"Project-Structure/#key-directories-explained","title":"Key Directories Explained","text":""},{"location":"Project-Structure/#srcopensageagents","title":"<code>src/opensage/agents/</code>","text":"<ul> <li>OpenSage base agent and tool description loading (<code>ToolLoader</code>)</li> </ul>"},{"location":"Project-Structure/#srcopensagesession","title":"<code>src/opensage/session/</code>","text":"<ul> <li>Session manager and per-session resource isolation</li> <li>Sandbox lifecycle management</li> <li>Dynamic agent management and ensemble management</li> </ul>"},{"location":"Project-Structure/#srcopensagesandbox","title":"<code>src/opensage/sandbox/</code>","text":"<ul> <li>Abstract sandbox interface</li> <li>Docker-based sandbox</li> <li>Kubernetes-based sandbox (under development)</li> <li><code>initializers/</code>: Sandbox initialization logic</li> </ul>"},{"location":"Project-Structure/#srcopensagebash_tools","title":"<code>src/opensage/bash_tools/</code>","text":"<ul> <li>Filesystem-discovered Skills (bash tools)</li> <li>Each Skill: <code>SKILL.md</code> + <code>scripts/</code> (+ optional <code>deps/</code>)</li> </ul>"},{"location":"Project-Structure/#srcopensagetoolbox","title":"<code>src/opensage/toolbox/</code>","text":"<ul> <li>Python-side tools, MCP toolsets, and wrappers used by agents</li> </ul>"},{"location":"Project-Structure/#srcopensageevaluations","title":"<code>src/opensage/evaluations/</code>","text":"<ul> <li><code>cybergym/</code>: CyberGym benchmark</li> <li><code>patchagent/</code>: PatchAgent benchmark</li> <li><code>secodeplt/</code>: SecCodePLT benchmark</li> <li><code>swe_bench_pro/</code> SWE-Bench Pro benchmark</li> </ul>"},{"location":"Project-Structure/#see-also","title":"See Also","text":"<ul> <li>Core Components - Component details</li> <li>Development Guides - How to add to the codebase</li> </ul>"},{"location":"Sandboxes/","title":"Sandbox System Guide","text":""},{"location":"Sandboxes/#overview","title":"Overview","text":"<p>The OpenSage sandbox system provides isolated execution environments through a pluggable backend architecture. This guide covers:</p> <ul> <li>Sandbox Backends: Execution engines (Native Docker, Remote Docker, Kubernetes under development)</li> <li>Sandbox Initializers: Functional types (main, neo4j, joern, gdb_mcp, etc.)</li> </ul>"},{"location":"Sandboxes/#sandbox-backends","title":"Sandbox Backends","text":"<p>Backends determine where and how containers are executed.</p>"},{"location":"Sandboxes/#available-backends","title":"Available Backends","text":"Backend Description Use Case native Local Docker daemon Development, testing remotedocker Remote Docker via SSH/TCP Remote execution, GPU servers k8s Kubernetes cluster (under development) Under development local No containers (direct execution) Debugging"},{"location":"Sandboxes/#selecting-a-backend","title":"Selecting a Backend","text":"<p>In configuration file:</p> <pre><code>[sandbox]\nbackend = \"native\"  # or \"remotedocker\", \"k8s\", \"local\"\n</code></pre>"},{"location":"Sandboxes/#remote-docker-backend","title":"Remote Docker Backend","text":"<p>Execute sandboxes on remote Docker daemons (e.g., GPU servers, cloud VMs).</p>"},{"location":"Sandboxes/#prerequisites","title":"Prerequisites","text":"<p>Local Machine:</p> <ul> <li>SSH client</li> </ul> <p>Remote Machine:</p> <ul> <li>Docker Engine 20.10+</li> <li>SSH server</li> <li>User in docker group</li> </ul>"},{"location":"Sandboxes/#ssh-setup","title":"SSH Setup","text":"<ol> <li> <p>Generate SSH key (if needed):    <pre><code>ssh-keygen -t ed25519\n</code></pre></p> </li> <li> <p>Copy key to remote:    <pre><code>ssh-copy-id username@remote-host\n</code></pre></p> </li> <li> <p>Configure SSH (<code>~/.ssh/config</code>):    <pre><code>Host my-remote-server\n    HostName remote-host.example.com\n    User username\n    IdentityFile ~/.ssh/id_ed25519\n</code></pre></p> </li> <li> <p>Verify:    <pre><code>ssh my-remote-server \"docker ps\"\n</code></pre></p> </li> </ol>"},{"location":"Sandboxes/#configuration","title":"Configuration","text":"<pre><code>[sandbox]\nbackend = \"remotedocker\"\ndocker_host = \"ssh://my-remote-server\"\ndocker_remote_host = \"192.0.2.100\"  # optional, auto-parsed if not set\n\n[sandbox.sandboxes.main]\nimage = \"ubuntu:22.04\"\n# Same as native backend\n</code></pre>"},{"location":"Sandboxes/#how-it-works","title":"How It Works","text":"<ul> <li>Image operations: Build/pull on remote Docker</li> <li>Volume creation: Data transferred via Docker API (put_archive)</li> <li>Port allocation: Dynamic (Docker assigns random ports)</li> <li>Service access: Local connects to <code>remote_host:dynamic_port</code></li> <li>Container execution: All containers run on remote host</li> </ul>"},{"location":"Sandboxes/#differences-from-native-backend","title":"Differences from Native Backend","text":"Feature Native Remote Docker Container location Local machine Remote machine Volume creation Instant (bind mount) Slower (data upload) Image build Local Remote (with context upload) Port allocation Loopback IP (127.0.0.x) Dynamic ports Concurrent tasks ~250 (IP limit) 1000+ (port-based)"},{"location":"Sandboxes/#extending-the-sandbox-system","title":"Extending the sandbox system","text":"<ul> <li>Adding a sandbox: Add a new sandbox type by writing a   sandbox initializer and registering it.</li> <li>Adding a new sandbox backend: Add a new   execution backend (e.g., a new container/runtime environment).</li> </ul>"},{"location":"Sandboxes/#see-also","title":"See Also","text":"<ul> <li>Core Components - Sandbox system details</li> <li>Development Guides - Other development guides</li> </ul>"},{"location":"Testing-Debugging/","title":"Testing &amp; Debugging","text":""},{"location":"Testing-Debugging/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\nuv run pytest tests/\n\n# Run specific test file\nuv run pytest tests/unit/test_session.py\n\n# Run with coverage\nuv run pytest --cov=src/opensage tests/\n</code></pre>"},{"location":"Testing-Debugging/#debugging-with-web-ui","title":"Debugging with Web UI","text":"<p>The web UI is the primary debugging tool:</p> <pre><code>uv run opensage web \\\n  --config /path/to/config.toml \\\n  --agent /path/to/agent_dir \\\n  --port 8080 \\\n  --neo4j_logging  # optional\n</code></pre>"},{"location":"Testing-Debugging/#debugging-sandboxes","title":"Debugging Sandboxes","text":"<pre><code># In your code\nsandbox = session.sandboxes.get_sandbox(\"main\")\nresult, exit_code = sandbox.run_command_in_container(\"pwd\")\nprint(f\"Working dir: {result}\")\n</code></pre>"},{"location":"Testing-Debugging/#logging","title":"Logging","text":"<p>OpenSage uses structured logging:</p> <pre><code>import logging\nlogger = logging.getLogger(__name__)\nlogger.info(\"Operation started\", extra={\"session_id\": session_id})\n</code></pre>"},{"location":"Testing-Debugging/#see-also","title":"See Also","text":"<ul> <li>Best Practices - Development best practices</li> </ul>"},{"location":"_Sidebar/","title":"Sidebar","text":""},{"location":"_Sidebar/#navigation","title":"Navigation","text":""},{"location":"_Sidebar/#home","title":"Home","text":"<ul> <li>Home</li> </ul>"},{"location":"_Sidebar/#getting-started","title":"Getting Started","text":"<ul> <li>Introduction</li> <li>Getting Started</li> <li>Project Structure</li> </ul>"},{"location":"_Sidebar/#entry-points","title":"Entry Points","text":"<ul> <li>Entry Points</li> <li>OpenSage Web Entry</li> <li>Evaluation Entry</li> </ul>"},{"location":"_Sidebar/#core-topics","title":"Core Topics","text":"<ul> <li>Core Components</li> </ul>"},{"location":"_Sidebar/#development","title":"Development","text":"<ul> <li>Development Guides</li> <li>Adding Tools</li> <li>Sandboxes</li> <li>Adding a Evaluation Benchmark</li> </ul>"},{"location":"_Sidebar/#practices","title":"Practices","text":"<ul> <li>Best Practices</li> <li>Tools</li> <li>Testing Debugging</li> </ul>"},{"location":"_Sidebar/#reference","title":"Reference","text":"<ul> <li>Configuration</li> <li>Contributing</li> </ul>"},{"location":"generated/cli/opensage-dependency-check/","title":"opensage dependency-check","text":"<pre><code>Usage: opensage dependency-check [OPTIONS]\n\n  Check OpenSage external dependencies.\n\nChecks for manually installed dependencies:\n  - CodeQL: Required for CodeQL static analysis features\n  - Docker: Required for native Docker sandbox backend\n  - kubectl: Required for Kubernetes sandbox backend (under development)\n\n  All dependencies are optional unless you plan to use the corresponding\n  features.\n\nOptions:\n  --help  Show this message and exit.\n</code></pre>"},{"location":"generated/cli/opensage-web/","title":"opensage web","text":"<pre><code>Usage: opensage web [OPTIONS]\n\n  Starts an OpenSage-flavored Web UI: prepare environment then serve agents.\n\nOptions:\n  --config FILE                   Path to OpenSage TOML config.  [required]\n  --agent DIRECTORY               Path to the agent folder (must contain agent\n                                  files).  [required]\n  --host TEXT                     Binding host for the server.  [default:\n                                  127.0.0.1]\n  --port INTEGER                  Port for the server.  [default: 8000]\n  --reload / --no-reload          Whether to enable auto reload.  [default:\n                                  reload]\n  --log_level [debug|info|warning|error|critical]\n                                  Logging level for the server.  [default:\n                                  INFO]\n  --neo4j_logging / --no-neo4j_logging\n                                  Enable Neo4j event logging via monkey\n                                  patches.  [default: no-neo4j_logging]\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"generated/cli/opensage/","title":"opensage","text":"<pre><code>Usage: opensage [OPTIONS] COMMAND [ARGS]...\n\n  OpenSage CLI tools.\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  dependency-check  Check OpenSage external dependencies.\n  web               Starts an OpenSage-flavored Web UI: prepare...\n</code></pre>"}]}